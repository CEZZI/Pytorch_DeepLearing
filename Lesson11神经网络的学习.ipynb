{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 11 神经网络的学习\n",
    "\n",
    "- 回顾梯度下降\n",
    "  1. 梯度下降的基本流程是什么，它是怎么找到损失函数的最小值的（写出流程）？  \n",
    "     对目标函数关于参数求偏导\n",
    "  2. 梯度下降中是如何迭代权重 的（写出公式）？\n",
    "       - $$w_{i+1} = w_i - \\alpha \\frac{\\partial}{\\partial w_i}L(w_1, w_2..., w_d, b)$$\n",
    "\n",
    "  3. 什么是梯度？什么是步长？\n",
    "       - 梯度：目标函数变化最快速度的反方向\n",
    "       - 步长：原点移动的长度\n",
    "      \n",
    "## 一、梯度下降中的两个关键问题\n",
    "\n",
    "### 1.找出梯度的方向和大小\n",
    "- 梯度向量是多元函数上，各个自变量的偏导数组成的向量，这些偏导数的具体值必须依赖于当前所在坐标点的值进行计算。\n",
    "\n",
    "### 2.进行迭代\n",
    "$$w_{(t+1)}=w_{(t)}-\\eta\\frac{\\partial}{\\partial w}L(w)$$\n",
    "是我们迭代权重的迭代公式，其中偏导数的大小影响整体梯度向量的大小，偏导数前的剪号影响整体梯度向量的方向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc61dd956bea47a7b3c00507e69dfd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='elev', options=(0, 15, 30), value=0), IntSlider(value=60, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#————————————————————————————绘图————————————————————————————\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "\n",
    "w1 = np.arange(-10,10,0.05)\n",
    "w2 = np.arange(-10,10,0.05)\n",
    "w1, w2 = np.meshgrid(w1, w2)\n",
    "lossfn = (2 - w1 - w2)**2 + (4 - 3*w1 - w2)**2\n",
    "#定义一个绘制三维图像的函数\n",
    "#elev表示上下旋转的角度\n",
    "#azim表示平行旋转的角度\n",
    "\n",
    "def plot_3D(elev=45,azim=60,X=w1,y=w2):\n",
    "    fig, ax = plt.subplots(1, 1,constrained_layout=True, figsize=(8, 8))\n",
    "    ax = plt.subplot(projection=\"3d\")\n",
    "    ax.plot_surface(w1, w2, lossfn, cmap='rainbow',alpha=0.7)\n",
    "    ax.view_init(elev=elev,azim=azim)\n",
    "    #ax.xticks([-10,-5,0,5,10])\n",
    "    #ax.set_xlabel(\"w1\",fontsize=20)\n",
    "    #ax.set_ylabel(\"w2\",fontsize=20)\n",
    "    #ax.set_zlabel(\"lossfn\",fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "from ipywidgets import interact,fixed\n",
    "interact(plot_3D,elev=[0,15,30],azip=(-180,180),X=fixed(w1),y=fixed(w2))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、找出距离和方向：反向传播\n",
    "\n",
    "### 1.反向传播的定义与价值\n",
    "\n",
    "我们是从左向右，**从输出向输入**，逐渐往前求解导数的表达式，并且我们所使用的节点上的张量，也是从后向前逐渐用到，这和正向传播的过程完全相反。这种从左到右，不断使用正向传播中的元素对梯度向量进行计算的方式，就是反向传播\n",
    "\n",
    "### 2.PyTorch实现反向传播\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(1.,requires_grad = True)\n",
    "z = x ** 2\n",
    "\n",
    "torch.autograd.grad(z,x)\n",
    "\n",
    "#=这里返回的是在函数y=x**2上，x=1时的导数值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对于单层神经网络，autograd.grad会非常有效。但深层神经网络就不太适合使用grad函数了。\n",
    "- PyTorch提供的基于autograd的反向传播功能，`lossfunction.backward()`来进行计算。\n",
    "  - `criterion = lossfunction.backward()`\n",
    "  - `loss = criterion(预测值,真实值.long())`\n",
    "    - 其中真实值必须是整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入库、数据、定义神经网络类，完成正向传播\n",
    "#继承nn.Module类完成正向传播\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3分类 500个样本，20个特征，共三层，第一层13个，第二层8个神经元\n",
    "\n",
    "# 生成数据\n",
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32)\n",
    "y = torch.randint(low=0,high=3,size=(500,),dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#————————————————————————————建立神经网络的架构————————————————————————————\n",
    "# logsoftmax + NLLLoss / CrossEntoryLoss\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=20,out_features=3) -> None:\n",
    "        super(Model,self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features,13,bias=True)\n",
    "        self.linear2 = nn.Linear(13,8,bias=True)\n",
    "        self.output = nn.Linear(8,out_features,bias=True)\n",
    "\n",
    "    # 定义向前传播的激活函数\n",
    "    def forward(self,x):\n",
    "        sigma1 = torch.relu(self.linear1(X))  # 一行完成\n",
    "        z2 = self.linear2(sigma1)\n",
    "        sigma2 = torch.sigmoid(z2)\n",
    "        zhat = self.output(sigma2)\n",
    "        # sigma3 = F.softmax(z3,dim=1)  # 不使用sigmoid\n",
    "        return zhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#————————————————————————————实例化神经网络类————————————————————————————\n",
    "input_ = X.shape[1] #特征的数目\n",
    "output_ = len(y.unique()) #分类的数目\n",
    "\n",
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_,out_features=output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0272, -0.1963, -0.5871],\n",
       "        [ 0.0023, -0.1955, -0.5866],\n",
       "        [-0.0770, -0.1754, -0.6096],\n",
       "        ...,\n",
       "        [-0.0045, -0.1997, -0.5832],\n",
       "        [-0.0225, -0.2066, -0.5743],\n",
       "        [-0.0200, -0.2079, -0.5665]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#————————————————————————————前向传播————————————————————————————\n",
    "zhat = net.forward(X)\n",
    "zhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1184, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#————————————————————————————定义损失函数————————————————————————————\n",
    "criterion = nn.CrossEntropyLoss()  # 实例化\n",
    "loss = criterion(zhat,y.long())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.linear1.weight.grad  \n",
    "# 还没有反向传播 所以不会返回任何值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3761e-05,  1.0973e-05,  6.8629e-06, -1.5644e-06,  1.9487e-05,\n",
       "         -5.9836e-06,  2.4508e-05,  1.1144e-05,  5.4205e-06, -7.4555e-06,\n",
       "          4.8241e-06,  1.8250e-05, -3.3542e-06,  1.3879e-05,  1.0864e-05,\n",
       "         -1.6416e-05,  1.5331e-05,  1.6790e-06,  2.5084e-05,  1.1616e-05],\n",
       "        [ 1.0856e-03,  1.7819e-03,  1.8401e-03,  1.2384e-03,  1.1341e-03,\n",
       "          1.0446e-03,  1.1615e-03,  1.1535e-03,  1.5216e-03,  1.1517e-03,\n",
       "          1.3311e-03,  1.3067e-03,  1.5875e-03,  1.2309e-03,  1.2933e-03,\n",
       "          1.3691e-03,  1.3698e-03,  1.2086e-03,  9.7722e-04,  1.0946e-03],\n",
       "        [-4.9581e-05, -1.1706e-04, -2.7976e-04, -9.5992e-05, -3.9125e-04,\n",
       "         -5.3201e-04, -2.9250e-04,  3.6262e-05, -6.4736e-04, -2.6931e-04,\n",
       "         -4.7741e-04, -2.4125e-04, -4.9524e-04, -1.6649e-04, -5.6666e-04,\n",
       "         -2.1780e-06, -2.2611e-04, -4.0575e-04, -1.9789e-04, -8.4060e-05],\n",
       "        [ 2.8862e-04,  3.1539e-04,  2.6116e-04,  2.2272e-04,  1.4244e-04,\n",
       "          2.4812e-04,  1.7803e-04,  1.4566e-04,  2.1103e-04,  1.5538e-04,\n",
       "          2.2131e-04,  1.1877e-04,  2.3349e-04,  1.8993e-04,  2.0416e-04,\n",
       "          1.3899e-04,  1.1681e-04,  5.8180e-05,  1.1365e-04, -8.1311e-05],\n",
       "        [-1.2175e-04, -2.8143e-04, -9.1680e-05, -4.2721e-04, -5.3307e-04,\n",
       "         -1.2704e-04, -2.2040e-04, -5.3240e-04,  6.8162e-04, -7.8137e-04,\n",
       "          3.3095e-05, -2.2148e-04,  5.2642e-04, -2.8532e-04,  4.6478e-04,\n",
       "         -3.5988e-04, -5.7301e-05, -2.9556e-04, -2.5908e-04, -1.8510e-04],\n",
       "        [-1.4632e-05, -2.8440e-06, -6.7717e-06, -5.4319e-06, -5.8513e-06,\n",
       "         -4.9693e-06, -2.6532e-06, -1.4529e-05, -2.5281e-06, -3.2893e-06,\n",
       "         -2.4123e-05, -2.2764e-05, -7.5330e-06, -8.2782e-06, -2.2472e-05,\n",
       "         -9.2901e-06, -1.1118e-05, -1.1828e-05, -2.3260e-06, -2.3553e-05],\n",
       "        [-1.5566e-03, -2.1099e-03, -2.7976e-03, -1.9382e-03, -1.7635e-03,\n",
       "         -1.9614e-03, -1.9726e-03, -1.6107e-03, -2.8637e-03, -1.5605e-03,\n",
       "         -1.9683e-03, -1.5955e-03, -2.1162e-03, -2.1565e-03, -2.6929e-03,\n",
       "         -1.4674e-03, -1.9416e-03, -2.1861e-03, -1.6585e-03, -1.3904e-03],\n",
       "        [-2.3564e-04, -6.4325e-04, -1.1398e-04, -4.8170e-04, -1.2088e-04,\n",
       "          2.1254e-04, -6.1852e-05, -4.0293e-04,  5.2122e-04, -6.1096e-04,\n",
       "          1.0351e-04, -5.1746e-04, -4.9734e-05, -2.1975e-04,  5.2342e-04,\n",
       "         -6.2856e-04, -3.7603e-05,  4.6683e-04, -1.1515e-04, -4.6756e-04],\n",
       "        [-6.9079e-05, -4.4012e-04,  3.9510e-05, -3.8246e-04, -9.2434e-05,\n",
       "         -1.2568e-04, -4.7672e-05, -2.0608e-04,  4.1945e-04, -4.0039e-04,\n",
       "          1.1607e-04, -2.5301e-04,  1.4926e-04, -1.1908e-04,  3.7067e-04,\n",
       "         -2.2442e-04, -1.2446e-04,  5.0318e-05, -1.9055e-04, -2.0050e-04],\n",
       "        [ 1.4176e-04,  1.2232e-04, -8.8881e-05,  2.2321e-05,  9.7528e-05,\n",
       "         -3.5822e-05, -2.1669e-04, -8.4875e-05, -2.3401e-05,  6.2169e-05,\n",
       "          1.7447e-05,  1.1245e-05,  5.5053e-05, -7.1963e-05,  2.6913e-05,\n",
       "          8.3244e-05,  6.3721e-05,  1.1999e-05, -1.6102e-04,  9.3378e-05],\n",
       "        [-2.6322e-04, -4.1693e-04, -1.3632e-04, -1.2537e-04, -2.1524e-04,\n",
       "         -1.3174e-04, -3.5550e-04, -9.3369e-05, -1.8275e-04, -5.6421e-04,\n",
       "         -7.8246e-05, -3.3732e-04, -2.0790e-04, -3.7083e-04,  4.7039e-05,\n",
       "         -3.0774e-04, -9.9300e-05, -2.0097e-05, -3.2527e-04, -7.3792e-05],\n",
       "        [-5.8857e-04, -9.7746e-04, -9.5070e-04, -8.1093e-04, -6.9681e-04,\n",
       "         -6.5957e-04, -8.8497e-04, -7.6163e-04, -9.1957e-04, -5.9797e-04,\n",
       "         -7.5536e-04, -7.9809e-04, -7.2524e-04, -7.8456e-04, -7.5570e-04,\n",
       "         -7.9351e-04, -5.9104e-04, -6.0169e-04, -5.2886e-04, -6.2523e-04],\n",
       "        [ 1.4253e-05,  2.1688e-05,  1.7813e-06,  1.8149e-05,  5.8913e-05,\n",
       "          3.5510e-05,  2.7867e-05,  6.1301e-05,  1.7346e-05,  6.1548e-05,\n",
       "          3.1055e-05,  2.6051e-05,  1.7560e-05,  7.5205e-06,  5.7556e-05,\n",
       "          8.5844e-06,  2.1002e-05,  5.4399e-05,  1.6375e-05,  2.5749e-05]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#————————————————————————————反向传播————————————————————————————\n",
    "loss.backward()\n",
    "\n",
    "net.linear1.weight.grad  # 返回相应的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-3bc18f71aa25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#如果希望能够重复进行反向传播，可以在进行第一次反向传播的时候加上参数retain_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mg:\\py\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\py\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m def grad(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "#与可以重复进行的正向传播不同，一次正向传播后，反向传播只能进行一次\n",
    "#如果希望能够重复进行反向传播，可以在进行第一次反向传播的时候加上参数retain_graph\n",
    "\n",
    "loss.backward(retain_graph=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们在定义损失函数时，并没有告诉损失函数哪些值是自变量，哪些是常数，那backward函数是怎么判断具体求解哪个对象的梯度的呢？\n",
    "\n",
    "    - 其实就是靠requires_grad。首先backward值会识别叶子节点，不在叶子上的变量是不会被backward考虑的。\n",
    "\n",
    "如果你的$w$是自己设置的，一定要设置requires_grad=True。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、移动坐标点\n",
    "\n",
    "### 1.走出第一步\n",
    "\n",
    "- 权重的迭代公式\n",
    " $$w_{(t+1)} = w_{t} - \\eta \\frac{\\partial L(w)}{\\partial w}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率一般都设置的很小\n",
    "\n",
    "#在这里，我们的数据是生成的随机数，为了让大家看出效果，所以我才设置了步长为10，正常不会使用这么大的步长\n",
    "#步长、学习率的英文是learning rate，所以常常简写为lr\n",
    "lr = 10\n",
    "\n",
    "dw = net.linear1.weight.grad\n",
    "w = net.linear1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1361, -0.1349,  0.2126, -0.1776, -0.0688, -0.1539,  0.1717,  0.0836,\n",
       "         -0.1117, -0.1727, -0.1296, -0.0437, -0.1140,  0.1625, -0.0944, -0.1458,\n",
       "         -0.0694, -0.2184, -0.1093, -0.1223],\n",
       "        [ 0.0156,  0.1284, -0.0311, -0.1675,  0.0580, -0.1265, -0.1407, -0.0775,\n",
       "         -0.1623, -0.0100,  0.1416, -0.0087,  0.0874, -0.2312, -0.2147, -0.0708,\n",
       "         -0.0409,  0.1033, -0.2260,  0.0605],\n",
       "        [-0.1904,  0.0396,  0.1562,  0.0337,  0.0831,  0.1581,  0.2300, -0.1414,\n",
       "          0.0927,  0.1922,  0.1415, -0.1953, -0.1402, -0.2140,  0.1160,  0.2213,\n",
       "         -0.2098,  0.1910, -0.2033, -0.0248],\n",
       "        [ 0.1728, -0.0446,  0.0170,  0.1563, -0.1918,  0.0491, -0.1145,  0.2009,\n",
       "         -0.2001,  0.0122,  0.1330, -0.1349, -0.1390,  0.0709, -0.1817,  0.1268,\n",
       "          0.0237, -0.2218,  0.0735, -0.1849],\n",
       "        [ 0.0311,  0.1454, -0.0359,  0.0963,  0.0004, -0.1640, -0.2077,  0.2006,\n",
       "          0.0634,  0.0834, -0.2064, -0.0212,  0.0316, -0.1893, -0.1924,  0.1244,\n",
       "          0.1427, -0.1291,  0.1248, -0.0286],\n",
       "        [ 0.0388, -0.1726, -0.1022, -0.1262, -0.1187, -0.1345, -0.1760,  0.0370,\n",
       "         -0.1783, -0.1646,  0.2091,  0.1847, -0.0885, -0.0751,  0.1794, -0.0570,\n",
       "         -0.0242, -0.0115, -0.1819,  0.1988],\n",
       "        [ 0.0247,  0.2818,  0.2680,  0.1553,  0.0478,  0.0564,  0.0643, -0.1690,\n",
       "          0.0325, -0.0566,  0.0457,  0.0752, -0.1117,  0.2346,  0.2634,  0.1831,\n",
       "          0.1587,  0.1010, -0.1114,  0.1318],\n",
       "        [ 0.0863,  0.2354, -0.2074,  0.2085,  0.1792,  0.0351,  0.0763,  0.0388,\n",
       "         -0.0335,  0.0634,  0.1264,  0.0410, -0.0188, -0.0008, -0.1879, -0.0882,\n",
       "          0.1832, -0.0008,  0.0269, -0.1816],\n",
       "        [ 0.1655,  0.0212, -0.0311, -0.2074,  0.1375, -0.0251, -0.1861,  0.0151,\n",
       "          0.1968,  0.1029, -0.0865, -0.0015,  0.0960, -0.0133, -0.1485,  0.1747,\n",
       "         -0.1897, -0.0363,  0.1063,  0.0283],\n",
       "        [ 0.1419,  0.1405, -0.0204,  0.0813,  0.0031,  0.0687,  0.1590,  0.1700,\n",
       "         -0.1683,  0.1138, -0.1859,  0.0230, -0.1631,  0.1045, -0.1739, -0.1916,\n",
       "         -0.2048, -0.0216, -0.0170, -0.0407],\n",
       "        [ 0.2016,  0.0664, -0.1449,  0.1708, -0.1601,  0.0663, -0.0309, -0.2028,\n",
       "         -0.1310, -0.1891, -0.1880, -0.0788, -0.0718,  0.1744, -0.1332,  0.0679,\n",
       "          0.2141,  0.1677, -0.0497, -0.2075],\n",
       "        [-0.0080,  0.0185, -0.0045,  0.0614, -0.0872,  0.2262,  0.1505, -0.1924,\n",
       "          0.1493, -0.1253,  0.1360,  0.0709,  0.1063,  0.2288, -0.0957,  0.2167,\n",
       "         -0.0107,  0.0252, -0.1947,  0.1268],\n",
       "        [-0.1230, -0.0690, -0.2193, -0.1499,  0.1905, -0.0640, -0.0772,  0.2177,\n",
       "         -0.0464,  0.0080, -0.0039, -0.0960, -0.0803, -0.1873,  0.1766, -0.1758,\n",
       "         -0.1039, -0.0213, -0.1750,  0.0196]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对任意w可以有\n",
    "w -= lr * dw\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.动量法Momentum\n",
    "\n",
    "我们让**上一步的梯度向量与现在这一点的梯度向量以加权的方式求和**，求解出受到上一步大小和方向影响的真实下降方向，再让坐标点向真实下降方向移动。  \n",
    "其中，对上一步的梯度向量加上的权重被称为动量参数$\\gamma$，对这一点的梯度向量加上的权重就是步长$\\eta$，真实移动的向量为$v$，被称为动量（Momentum）。将上述过程使用公式表示，则有：\n",
    "\n",
    "$$v_{(t)}=\\gamma v_{(t-1)} - \\eta\\frac{L}{\\partial w}$$\n",
    "$$w_{(t+1)}=w_{(t)}+v_{(t)}$$\n",
    "\n",
    "在第一步中，没有历史梯度方向，因此第一步的真实方向就是起始点梯度的反方向，$v_0=0$ 。其中$v_{(t-1)}$代表了之前所有步骤所累积的动量和。\n",
    "\n",
    "- 一直往一个方向走，就迈大步走；换一个方向就迈小步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# momentum\n",
    "\n",
    "# v(t) = gamma *v(t-1) - lr *dw\n",
    "# w(t+1) = w(t) + v(t)\n",
    "\n",
    "lr = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "dw = net.linear1.weight.grad\n",
    "w = net.linear1.weight.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t =1 , 走第一步，进行首次迭代的时候需要一个v0\n",
    "\n",
    "dw.shape\n",
    "\n",
    "v = torch.zeros(dw.shape[0],dw.shape[1])\n",
    "#v要能够跟dw相减，因此必须和dw保持相同的结构，初始v为0，但后续v会越来越大\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1361, -0.1349,  0.2126, -0.1776, -0.0688, -0.1539,  0.1717,  0.0836,\n",
       "         -0.1117, -0.1727, -0.1296, -0.0437, -0.1140,  0.1625, -0.0944, -0.1458,\n",
       "         -0.0694, -0.2184, -0.1093, -0.1223],\n",
       "        [ 0.0157,  0.1286, -0.0309, -0.1673,  0.0581, -0.1264, -0.1406, -0.0773,\n",
       "         -0.1622, -0.0099,  0.1417, -0.0086,  0.0876, -0.2311, -0.2146, -0.0707,\n",
       "         -0.0408,  0.1034, -0.2259,  0.0606],\n",
       "        [-0.1904,  0.0396,  0.1561,  0.0337,  0.0831,  0.1581,  0.2300, -0.1414,\n",
       "          0.0926,  0.1921,  0.1414, -0.1953, -0.1403, -0.2140,  0.1159,  0.2213,\n",
       "         -0.2098,  0.1909, -0.2033, -0.0248],\n",
       "        [ 0.1728, -0.0446,  0.0170,  0.1563, -0.1918,  0.0492, -0.1144,  0.2009,\n",
       "         -0.2001,  0.0123,  0.1330, -0.1349, -0.1390,  0.0709, -0.1817,  0.1268,\n",
       "          0.0237, -0.2218,  0.0735, -0.1849],\n",
       "        [ 0.0311,  0.1454, -0.0359,  0.0962,  0.0003, -0.1640, -0.2077,  0.2005,\n",
       "          0.0635,  0.0833, -0.2064, -0.0212,  0.0317, -0.1893, -0.1923,  0.1244,\n",
       "          0.1427, -0.1291,  0.1248, -0.0286],\n",
       "        [ 0.0388, -0.1726, -0.1022, -0.1262, -0.1187, -0.1345, -0.1760,  0.0370,\n",
       "         -0.1783, -0.1646,  0.2091,  0.1847, -0.0885, -0.0751,  0.1794, -0.0570,\n",
       "         -0.0242, -0.0115, -0.1819,  0.1988],\n",
       "        [ 0.0245,  0.2816,  0.2678,  0.1551,  0.0477,  0.0562,  0.0641, -0.1692,\n",
       "          0.0323, -0.0568,  0.0456,  0.0751, -0.1120,  0.2344,  0.2631,  0.1829,\n",
       "          0.1585,  0.1007, -0.1115,  0.1316],\n",
       "        [ 0.0863,  0.2354, -0.2075,  0.2085,  0.1792,  0.0351,  0.0763,  0.0388,\n",
       "         -0.0335,  0.0633,  0.1264,  0.0410, -0.0188, -0.0008, -0.1879, -0.0883,\n",
       "          0.1832, -0.0008,  0.0269, -0.1817],\n",
       "        [ 0.1654,  0.0212, -0.0311, -0.2074,  0.1375, -0.0251, -0.1861,  0.0151,\n",
       "          0.1969,  0.1029, -0.0864, -0.0015,  0.0960, -0.0133, -0.1484,  0.1747,\n",
       "         -0.1897, -0.0363,  0.1063,  0.0283],\n",
       "        [ 0.1419,  0.1405, -0.0204,  0.0813,  0.0031,  0.0687,  0.1590,  0.1700,\n",
       "         -0.1683,  0.1138, -0.1859,  0.0230, -0.1631,  0.1045, -0.1739, -0.1915,\n",
       "         -0.2048, -0.0216, -0.0170, -0.0407],\n",
       "        [ 0.2016,  0.0664, -0.1449,  0.1708, -0.1601,  0.0663, -0.0309, -0.2029,\n",
       "         -0.1310, -0.1891, -0.1880, -0.0789, -0.0718,  0.1743, -0.1332,  0.0678,\n",
       "          0.2141,  0.1677, -0.0498, -0.2075],\n",
       "        [-0.0080,  0.0184, -0.0046,  0.0613, -0.0873,  0.2261,  0.1504, -0.1925,\n",
       "          0.1492, -0.1254,  0.1359,  0.0708,  0.1062,  0.2288, -0.0957,  0.2166,\n",
       "         -0.0107,  0.0251, -0.1947,  0.1267],\n",
       "        [-0.1230, -0.0690, -0.2193, -0.1499,  0.1905, -0.0640, -0.0772,  0.2177,\n",
       "         -0.0464,  0.0080, -0.0039, -0.0960, -0.0803, -0.1873,  0.1766, -0.1758,\n",
       "         -0.1039, -0.0213, -0.1750,  0.0196]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#==========分割cell，不然重复运行的时候w会每次都被覆盖掉=============\n",
    "#对任意w可以有\n",
    "v = gamma * v - lr * dw\n",
    "w -= v\n",
    "w\n",
    "#不难发现，当加入gamma之后，即便是较小的步长，也可以让w发生变化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.torch.optim实现带动量的梯度下降\n",
    "\n",
    "**建立神经网络的步骤**\n",
    "- 导入库\n",
    "- 确定数据、超参数的确定\n",
    "- 定义神经网络的架构类Model,定义类Model需要输入的参数\n",
    "- 实例化神经网络的类 --> 让神经网络准备好进行正向传播\n",
    "- 定义损失函数\n",
    "- 定义优化算法\n",
    "  - `optim.SGD(net.parameters(), lr=学习率, momentum =动量参数)`\n",
    "- 前项传播\n",
    "- 本轮向前传播的损失函数值\n",
    "- 反向传播-得到了梯度\n",
    "- 更新权重（和动量）\n",
    "- 清空梯度 - 清楚原来计算的，基于上一个点的坐标计算的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000001F3F48641C8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#————————————————————————————前面代码的整合————————————————————————————\n",
    "#导入库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#确定数据、确定优先需要设置的值\n",
    "lr = 0.1\n",
    "gamma = 0.9\n",
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32) * 100\n",
    "y = torch.randint(low=0,high=3,size=(500,1),dtype=torch.float32)\n",
    "input_ = X.shape[1] #特征的数目\n",
    "output_ = len(y.unique()) #分类的数目\n",
    "\n",
    "#定义神经网路的架构\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=10,out_features=2):\n",
    "        super(Model,self).__init__() #super(请查找这个类的父类，请使用找到的父类替换现在的类)\n",
    "        self.linear1 = nn.Linear(in_features,13,bias=True) #输入层不用写，这里是隐藏层的第一层\n",
    "        self.linear2 = nn.Linear(13,8,bias=True)\n",
    "        self.output = nn.Linear(8,out_features,bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z1 = self.linear1(x)\n",
    "        sigma1 = torch.relu(z1)\n",
    "        z2 = self.linear2(sigma1)\n",
    "        sigma2 = torch.sigmoid(z2)\n",
    "        z3 = self.output(sigma2)\n",
    "        #sigma3 = F.softmax(z3,dim=1)\n",
    "        return z3\n",
    "\n",
    "#实例化神经网络，调用优化算法需要的参数\n",
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_, out_features=output_)\n",
    "net.parameters()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.3656e-01, -1.3459e-01,  2.1281e-01, -1.7763e-01, -6.8218e-02,\n",
      "         -1.5410e-01,  1.7245e-01,  8.3885e-02, -1.1153e-01, -1.7294e-01,\n",
      "         -1.2947e-01, -4.3138e-02, -1.1413e-01,  1.6295e-01, -9.4082e-02,\n",
      "         -1.4629e-01, -6.8982e-02, -2.1836e-01, -1.0859e-01, -1.2199e-01],\n",
      "        [ 4.8127e-02,  1.8186e-01,  2.4149e-02, -1.3032e-01,  9.2056e-02,\n",
      "         -9.5202e-02, -1.0584e-01, -4.2852e-02, -1.1669e-01,  2.4581e-02,\n",
      "          1.8152e-01,  3.0500e-02,  1.3506e-01, -1.9425e-01, -1.7591e-01,\n",
      "         -2.9751e-02,  2.0485e-04,  1.3957e-01, -1.9666e-01,  9.3293e-02],\n",
      "        [-1.9192e-01,  3.6070e-02,  1.4778e-01,  3.0845e-02,  7.1393e-02,\n",
      "          1.4217e-01,  2.2122e-01, -1.4032e-01,  7.3255e-02,  1.8409e-01,\n",
      "          1.2716e-01, -2.0253e-01, -1.5509e-01, -2.1899e-01,  9.8980e-02,\n",
      "          2.2123e-01, -2.1659e-01,  1.7880e-01, -2.0922e-01, -2.7275e-02],\n",
      "        [ 1.8144e-01, -3.5166e-02,  2.4801e-02,  1.6299e-01, -1.8755e-01,\n",
      "          5.6587e-02, -1.0911e-01,  2.0523e-01, -1.9378e-01,  1.6899e-02,\n",
      "          1.3966e-01, -1.3137e-01, -1.3201e-01,  7.6554e-02, -1.7558e-01,\n",
      "          1.3096e-01,  2.7182e-02, -2.2010e-01,  7.6883e-02, -1.8731e-01],\n",
      "        [ 2.7419e-02,  1.3699e-01, -3.8687e-02,  8.3463e-02, -1.5634e-02,\n",
      "         -1.6781e-01, -2.1426e-01,  1.8463e-01,  8.3891e-02,  5.9950e-02,\n",
      "         -2.0538e-01, -2.7832e-02,  4.7442e-02, -1.9782e-01, -1.7842e-01,\n",
      "          1.1362e-01,  1.4101e-01, -1.3794e-01,  1.1704e-01, -3.4108e-02],\n",
      "        [ 3.8388e-02, -1.7268e-01, -1.0235e-01, -1.2634e-01, -1.1883e-01,\n",
      "         -1.3463e-01, -1.7610e-01,  3.6543e-02, -1.7834e-01, -1.6471e-01,\n",
      "          2.0834e-01,  1.8400e-01, -8.8723e-02, -7.5378e-02,  1.7877e-01,\n",
      "         -5.7259e-02, -2.4522e-02, -1.1822e-02, -1.8196e-01,  1.9812e-01],\n",
      "        [-2.2011e-02,  2.1847e-01,  1.8410e-01,  9.7177e-02, -5.0634e-03,\n",
      "         -2.4731e-03,  5.1408e-03, -2.1733e-01, -5.3375e-02, -1.0346e-01,\n",
      "         -1.3303e-02,  2.7354e-02, -1.7523e-01,  1.6994e-01,  1.8259e-01,\n",
      "          1.3907e-01,  1.0041e-01,  3.5377e-02, -1.6114e-01,  9.0056e-02],\n",
      "        [ 7.9232e-02,  2.1614e-01, -2.1087e-01,  1.9407e-01,  1.7559e-01,\n",
      "          4.1470e-02,  7.4482e-02,  2.6737e-02, -1.7872e-02,  4.5040e-02,\n",
      "          1.2947e-01,  2.5483e-02, -2.0320e-02, -7.3942e-03, -1.7221e-01,\n",
      "         -1.0705e-01,  1.8203e-01,  1.3179e-02,  2.3468e-02, -1.9567e-01],\n",
      "        [ 1.6338e-01,  8.0209e-03, -2.9885e-02, -2.1884e-01,  1.3471e-01,\n",
      "         -2.8901e-02, -1.8757e-01,  8.9256e-03,  2.0940e-01,  9.0927e-02,\n",
      "         -8.2969e-02, -9.0893e-03,  1.0047e-01, -1.6897e-02, -1.3736e-01,\n",
      "          1.6801e-01, -1.9342e-01, -3.4822e-02,  1.0057e-01,  2.2273e-02],\n",
      "        [ 1.4611e-01,  1.4414e-01, -2.3093e-02,  8.1946e-02,  5.9792e-03,\n",
      "          6.7672e-02,  1.5254e-01,  1.6742e-01, -1.6896e-01,  1.1571e-01,\n",
      "         -1.8538e-01,  2.3316e-02, -1.6147e-01,  1.0230e-01, -1.7314e-01,\n",
      "         -1.8906e-01, -2.0286e-01, -2.1210e-02, -2.1799e-02, -3.7921e-02],\n",
      "        [ 1.9375e-01,  5.3921e-02, -1.4900e-01,  1.6709e-01, -1.6652e-01,\n",
      "          6.2363e-02, -4.1574e-02, -2.0565e-01, -1.3649e-01, -2.0600e-01,\n",
      "         -1.9032e-01, -8.8942e-02, -7.8061e-02,  1.6323e-01, -1.3174e-01,\n",
      "          5.8638e-02,  2.1117e-01,  1.6707e-01, -5.9492e-02, -2.0973e-01],\n",
      "        [-2.5644e-02, -1.0818e-02, -3.3051e-02,  3.7071e-02, -1.0809e-01,\n",
      "          2.0642e-01,  1.2396e-01, -2.1523e-01,  1.2172e-01, -1.4323e-01,\n",
      "          1.1334e-01,  4.6931e-02,  8.4553e-02,  2.0530e-01, -1.1833e-01,\n",
      "          1.9287e-01, -2.8398e-02,  7.1443e-03, -2.1055e-01,  1.0805e-01],\n",
      "        [-1.2258e-01, -6.8325e-02, -2.1929e-01, -1.4939e-01,  1.9226e-01,\n",
      "         -6.2922e-02, -7.6377e-02,  2.1955e-01, -4.5838e-02,  9.8011e-03,\n",
      "         -2.9400e-03, -9.5241e-02, -7.9775e-02, -1.8708e-01,  1.7828e-01,\n",
      "         -1.7552e-01, -1.0328e-01, -1.9697e-02, -1.7449e-01,  2.0408e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.3508e-01,  1.5439e-01, -1.9350e-01, -6.8777e-02,  1.3787e-01,\n",
      "        -1.8474e-01,  1.2763e-01,  1.8031e-01,  9.5152e-02, -1.2660e-01,\n",
      "         1.4317e-01, -1.4945e-01,  3.4258e-05], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0854,  0.0825,  0.1020, -0.0941,  0.2054,  0.2645, -0.2198, -0.0169,\n",
      "          0.0017, -0.2714, -0.1154,  0.0410, -0.0668],\n",
      "        [-0.2668,  0.1752, -0.2743,  0.1611, -0.1190,  0.0476,  0.0036,  0.2185,\n",
      "         -0.1021,  0.2397,  0.1055, -0.0704, -0.1420],\n",
      "        [ 0.2249, -0.2563, -0.2121, -0.0678,  0.1129,  0.0035,  0.0988,  0.2494,\n",
      "          0.1891, -0.0448,  0.1583,  0.0126,  0.2220],\n",
      "        [-0.2095, -0.1938, -0.0562, -0.2183, -0.2483,  0.2078,  0.2142,  0.0754,\n",
      "         -0.2532,  0.1142,  0.0657, -0.0808,  0.2725],\n",
      "        [ 0.2063,  0.0870, -0.2641,  0.2648,  0.1443, -0.2759,  0.0101,  0.1611,\n",
      "          0.2489, -0.1175,  0.0537, -0.0365,  0.2095],\n",
      "        [ 0.2333, -0.0148, -0.2440,  0.0268,  0.1815,  0.2528, -0.2730,  0.2145,\n",
      "          0.0205, -0.2279,  0.0727, -0.2309, -0.1754],\n",
      "        [-0.1644, -0.0508,  0.0548,  0.0702, -0.1867, -0.0818,  0.2041, -0.0269,\n",
      "         -0.1098, -0.0464,  0.1511,  0.0050, -0.1364],\n",
      "        [ 0.2180, -0.0104,  0.1469, -0.0562, -0.2288, -0.0920,  0.1706, -0.1874,\n",
      "         -0.1059, -0.0818, -0.2628, -0.2723,  0.1970]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0900, -0.0597,  0.0268, -0.0173,  0.0065,  0.0228, -0.1408,  0.1188],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1259,  0.1116, -0.0097, -0.1100,  0.0427,  0.3335, -0.2140, -0.2908],\n",
      "        [-0.0166,  0.0617, -0.2413,  0.0719, -0.0847, -0.0331, -0.1862,  0.1859],\n",
      "        [-0.1704,  0.1227,  0.3419,  0.0164, -0.2700, -0.0598, -0.2827, -0.3440]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0156, -0.0730, -0.2637], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 一次性导入现有神经网络架构的所有参数\n",
    "for x in net.parameters():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化算法\n",
    "opt = optim.SGD(net.parameters() #要优化的参数是哪些？\n",
    "               , lr=lr #学习率\n",
    "               , momentum = gamma #动量参数\n",
    "               )\n",
    "\n",
    "# 第一参数是参数,学习率,动量参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来开始进行一轮梯度下降：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0529, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 0.1350, -0.1350,  0.2109, -0.1778, -0.0689, -0.1544,  0.1707,  0.0825,\n",
      "        -0.1120, -0.1732])\n"
     ]
    }
   ],
   "source": [
    "#————————————————————————————重要❤：迭代方法————————————————————————————\n",
    "# 前向传播\n",
    "zhat = net.forward(X)\n",
    "\n",
    "# 计算损失函数\n",
    "loss = criterion(zhat,y.reshape(500).long())\n",
    "loss.backward()\n",
    "\n",
    "# 走一步\n",
    "opt.step()  # 更新权重w，从这一瞬间开始，坐标点就发生了变化，所有的梯度必须重新计算\n",
    "opt.zero_grad() #清除原来储存好的，基于上一个坐标点计算的梯度，为下一次计算梯度腾出空间\n",
    "\n",
    "print(loss)\n",
    "print(net.linear1.weight.data[0][:10])\n",
    "\n",
    "\n",
    "# 每运行一次 loss都会减少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、开始迭代：batch_size与epoches\n",
    "\n",
    "### 1.小批量梯度下降\n",
    "\n",
    "小批量随机梯度下降（简写为mini-batch SGD）。小批量随机梯度下降的求解与迭代流程与传统梯度下降（GD）基本一致，不过二者在迭代权重时使用的数据这一点上存在巨大的不同。\n",
    "- 传统梯度下降在每次进行权重迭代（即循环）时都使用全部数据，每次迭代所使用的数据也都一致。\n",
    "- 随机梯度下降，每个批次里只有一个样本,梯度下降的迭代轨迹就会变得异常不稳定,计算过慢\n",
    "- 而mini-batch SGD是每次迭代前都会从整体采样一批固定数目的样本组成批次（batch）$B$，并用$B$中的样本进行梯度计算，以减少样本量。\n",
    "  - mini-batch SGD更可能找到全局最小值\n",
    "  - mini-batch SGD可以提升神经网络的计算效率，让神经网络计算更快\n",
    "\n",
    "### 2.batch_size与epoches\n",
    "\n",
    "- 选择的批量batch含有的样本数被称为`batch_size`，这个尺寸一定是小于数据量的某个正整数值\n",
    "- `epoch`是衡量训练数据被使用次数的单位，\n",
    "  - 一个epoch表示优化算法将全部训练数据都使用了一次，我们常使用“完成1个epoch需要n次迭代“这样的语言\n",
    "\n",
    "```\n",
    "for epochs in range(epoch):\n",
    "    for batch in range(batch):\n",
    "        zhat = net.forward(X)  # 最后一个线性层的输出结果，前向传播\n",
    "        loss = criterion(zhat,y.reshape(500).long())  # 计算损失函数\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step() # 走一步\n",
    "        opt.zero_grad()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.TensorDataset与DataLoader\n",
    "\n",
    "torch中用于预处理的两个类\n",
    "- `DataLoader` 用与切割小批量的类\n",
    "  - `dataset = DataLoader(data,batch_size=抽样的大小,shuffle=是否打乱抽样,drop_last=是否舍弃最后一个batch)`\n",
    "    - bs 输入正数即可 \n",
    "  - 属性`batch_size`查看现在的batch_size是多少\n",
    "  - `len(dataset)`返回多少个batch\n",
    "  - `len(dataset.dataset)` 返回有多少个样本\n",
    "- TensorDataset 合并数据：要求数据的第一维度上的值相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "a = torch.randn(500,2,3)  # 三维数据\n",
    "b = torch.randn(500,3,4,5)  # 四维数据\n",
    "c = torch.randn(500,1)  # 二维数据\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.1243,  0.4218, -0.0191],\n",
      "        [-1.1607, -0.4629,  0.7467]]), tensor([[[ 0.1839,  0.9627,  1.4169, -0.5208, -0.0273],\n",
      "         [-0.0235, -0.4743,  0.7232,  0.1129, -0.9538],\n",
      "         [ 0.6910, -1.3103,  0.2457,  0.4946,  0.1170],\n",
      "         [-0.3008, -0.7154,  0.8117,  0.7465, -0.4695]],\n",
      "\n",
      "        [[ 0.0158, -0.0928,  0.0184, -0.3890, -0.3316],\n",
      "         [ 0.8901,  0.6421, -0.8500, -0.3790, -0.8492],\n",
      "         [-0.4432, -0.6814,  0.5305, -1.1311,  0.9367],\n",
      "         [-0.4199, -1.5849,  1.8307, -0.5568,  1.1463]],\n",
      "\n",
      "        [[ 0.4434, -0.5125, -1.1083,  0.9996,  0.5958],\n",
      "         [-0.6915, -0.9653,  0.0378,  1.3866, -0.9301],\n",
      "         [ 1.8503, -0.3203, -0.6716, -0.3436, -0.2124],\n",
      "         [ 0.5932,  0.4367, -1.8365,  0.6224, -1.4629]]]), tensor([0.4655]))\n"
     ]
    }
   ],
   "source": [
    "# 被合并的数据第一维度上的值相等\n",
    "TensorDataset(a,b,c)\n",
    "for x in TensorDataset(a,b,c):\n",
    "    print(x)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x1f3f4851588>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  TensorDataset(b,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[80.5354, 19.9040, 97.5853,  ...,  1.1728, 25.7179, 22.7224],\n",
      "        [60.7616, 90.6643, 55.3998,  ..., 81.2087,  6.0260, 70.8609],\n",
      "        [ 7.0843, 58.0655, 83.0440,  ..., 89.9817,  3.2177, 43.9011],\n",
      "        ...,\n",
      "        [79.8613, 67.0805, 72.9771,  ..., 12.6831, 13.0960, 85.5574],\n",
      "        [66.3387, 89.4342, 95.2700,  ..., 20.2950, 39.9825, 23.0228],\n",
      "        [70.8147, 10.6863, 12.6333,  ...,  1.5278, 47.2199,  7.1780]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "for x in DataLoader(data):\n",
    "    print(X)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[ 5.0350e-01, -2.5785e-01, -7.4411e-01,  4.8481e-01, -3.3028e-01],\n",
      "          [ 1.7720e+00,  4.3487e-01,  2.4103e+00,  1.0993e+00,  1.6905e-01],\n",
      "          [-1.5238e+00, -2.7925e-01,  3.0360e-01, -1.5479e+00, -1.4451e+00],\n",
      "          [ 1.7829e-01,  7.3875e-01, -5.7917e-01,  3.4826e-01,  1.8869e+00]],\n",
      "\n",
      "         [[-1.4717e+00,  9.7736e-01,  1.5970e-01, -5.6110e-01,  1.6295e+00],\n",
      "          [-1.0495e+00, -6.5790e-01,  1.0529e+00,  1.3748e-01,  7.9938e-02],\n",
      "          [-4.2732e-01,  9.6678e-01,  5.8481e-02,  1.1538e+00, -2.2755e+00],\n",
      "          [ 5.1710e-01, -1.6784e+00,  2.7139e-01,  8.8691e-02,  1.3170e+00]],\n",
      "\n",
      "         [[ 3.2207e-01,  9.4099e-01, -1.0966e+00,  7.2319e-01,  1.6767e-01],\n",
      "          [ 1.2207e+00, -1.8586e-01,  4.8526e-01,  1.1862e+00,  2.0376e-03],\n",
      "          [ 7.3086e-02,  1.0813e+00, -1.1925e+00,  3.0230e+00, -9.3491e-01],\n",
      "          [ 1.4111e+00, -1.0762e+00,  2.5075e+00,  7.5943e-01,  1.5455e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.3630e+00, -1.6867e+00, -2.0737e-03,  3.3542e+00, -2.7244e-01],\n",
      "          [-6.1811e-01, -5.3039e-01, -3.7905e-01,  5.1550e-01, -1.1860e+00],\n",
      "          [-1.2890e+00, -1.2884e+00,  2.0349e-01, -9.4429e-02,  4.5135e-01],\n",
      "          [ 4.2555e-01,  5.6311e-01, -1.5982e+00, -7.9022e-01, -1.3331e+00]],\n",
      "\n",
      "         [[ 1.1428e+00,  5.2188e-01,  5.2130e-01,  2.2404e-01,  2.0166e+00],\n",
      "          [ 1.5584e+00, -6.2043e-01,  8.4986e-01, -1.2924e+00, -1.9900e+00],\n",
      "          [-1.5591e-01, -4.9011e-01,  4.5762e-02, -1.7449e+00,  1.1310e+00],\n",
      "          [ 8.6711e-01,  7.7782e-02,  1.7277e+00,  8.7309e-01,  2.0966e-01]],\n",
      "\n",
      "         [[ 7.7658e-01, -9.6628e-01,  1.7987e+00,  8.2814e-01,  3.6796e-01],\n",
      "          [ 1.5299e-01,  2.5997e-01,  1.6839e+00, -7.7585e-01, -3.2366e-01],\n",
      "          [-5.3387e-01,  2.2341e+00,  7.7990e-01,  5.3513e-02,  1.6469e+00],\n",
      "          [-1.5740e-01,  5.6795e-01,  1.3129e+00, -3.4386e-01,  1.6124e+00]]],\n",
      "\n",
      "\n",
      "        [[[-4.8740e-01,  1.6471e-01,  4.2945e-01,  1.2615e+00,  4.5063e-01],\n",
      "          [ 2.6484e+00,  1.5645e-02, -8.1997e-01, -5.1001e-02, -1.7393e+00],\n",
      "          [ 1.5206e+00, -9.1511e-01, -1.0201e+00, -8.9642e-01, -6.8553e-01],\n",
      "          [ 1.7335e-01,  6.6819e-01,  5.5735e-01,  1.2099e+00, -2.9421e-01]],\n",
      "\n",
      "         [[-6.7265e-01,  4.0750e-01, -3.3081e-01,  2.7228e-02,  5.7084e-01],\n",
      "          [-2.4880e-01, -3.7084e-01,  2.0657e-01, -1.9909e+00,  8.6548e-01],\n",
      "          [-8.0598e-01, -9.2679e-02,  2.3252e+00, -5.4218e-01, -2.6223e-01],\n",
      "          [ 1.0185e+00, -3.5618e-01,  8.6217e-01, -1.1446e+00,  9.1983e-01]],\n",
      "\n",
      "         [[-7.5306e-01,  7.3131e-01,  1.4980e+00,  1.2339e+00,  2.0127e-01],\n",
      "          [ 2.0884e-01, -1.5995e+00, -6.7840e-01,  2.8594e-01, -4.2403e-01],\n",
      "          [-6.5104e-01, -1.1004e+00, -1.5976e-01, -1.2596e+00,  1.4861e+00],\n",
      "          [ 4.9292e-01,  5.9736e-01, -1.1997e+00, -8.2718e-01,  7.8886e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.8896e-02,  8.3920e-01, -2.3376e+00,  2.1929e+00,  5.8113e-01],\n",
      "          [-2.4528e-01, -8.9288e-01,  3.0992e-01, -4.6345e-01,  2.1949e-01],\n",
      "          [ 2.5010e-01, -1.2008e+00,  2.3956e-01,  9.2276e-02, -3.8891e-01],\n",
      "          [-2.6240e+00, -5.4750e-01,  3.9188e-01,  9.7985e-01, -5.8805e-02]],\n",
      "\n",
      "         [[ 4.4465e-01,  6.8304e-01,  7.9684e-01,  3.9701e-01,  1.2157e-01],\n",
      "          [-2.9806e-01, -6.3924e-01,  1.3496e+00,  3.9614e-01, -4.3762e-01],\n",
      "          [ 1.6273e-01,  1.8924e+00,  1.2231e+00,  3.2246e-01, -5.0057e-01],\n",
      "          [-1.8350e+00, -1.5065e-01,  1.1107e+00, -9.2567e-01, -1.4545e+00]],\n",
      "\n",
      "         [[ 4.8218e-01, -2.6913e+00,  5.5900e-01, -1.2072e+00,  5.8263e-01],\n",
      "          [ 1.5440e+00, -1.1371e+00,  3.7166e-01,  1.0848e+00, -3.5193e-01],\n",
      "          [ 9.9344e-02,  3.9546e-01,  3.5991e-01, -4.1865e-02,  2.2551e+00],\n",
      "          [ 1.7219e-02, -2.0539e-01,  1.5024e+00, -1.1394e+00,  4.4288e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5539e+00, -9.4214e-01,  8.1939e-01,  4.4863e-01, -3.2344e-01],\n",
      "          [ 6.2217e-01, -6.5734e-01, -2.3567e-01,  5.3283e-02, -6.4533e-01],\n",
      "          [ 1.6801e+00, -5.3849e-01, -9.8710e-01,  5.6109e-01, -1.1857e+00],\n",
      "          [-1.3416e+00,  7.0267e-01, -1.4405e-02,  6.9704e-01, -2.0071e-01]],\n",
      "\n",
      "         [[ 3.5139e-01, -1.1216e+00, -1.8821e+00, -1.3019e-02,  2.6233e-01],\n",
      "          [-8.9947e-01, -3.9430e-01, -7.8648e-01, -2.8928e+00, -1.3541e+00],\n",
      "          [-1.5139e+00, -5.2877e-01,  3.9048e-01, -1.3987e+00,  1.3462e+00],\n",
      "          [ 2.3353e+00,  1.2389e+00,  8.0311e-01, -5.6267e-01,  2.3738e+00]],\n",
      "\n",
      "         [[ 6.0670e-01,  1.0597e+00, -1.8844e+00,  1.4979e+00, -5.5418e-01],\n",
      "          [ 2.9369e-01,  4.9255e-01, -6.0244e-01, -1.1911e+00, -9.7272e-01],\n",
      "          [ 2.8215e-01, -4.0013e-01, -1.1641e+00, -1.0260e+00, -1.6994e+00],\n",
      "          [-7.6654e-01,  5.9214e-01,  2.5437e-01,  1.4644e+00,  2.9941e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.6868e-01,  2.2219e+00, -9.7611e-01,  2.6286e-01,  4.3583e-01],\n",
      "          [ 1.8482e+00, -4.1877e-01, -3.5977e-01, -1.5739e+00, -6.4119e-01],\n",
      "          [-6.0099e-02, -7.9360e-01,  1.2395e+00, -5.0985e-01, -5.9766e-01],\n",
      "          [-4.8441e-01, -1.6723e+00, -3.1037e-01, -1.0350e+00,  1.0991e-01]],\n",
      "\n",
      "         [[ 1.4069e+00,  3.2602e-01, -1.0910e+00, -1.2348e-01, -8.1014e-01],\n",
      "          [ 1.2272e+00, -8.9080e-01,  1.0696e+00,  7.2635e-01, -5.6686e-02],\n",
      "          [ 1.1009e+00,  9.2005e-01, -1.5877e+00,  1.0641e-01, -9.7846e-01],\n",
      "          [ 7.0712e-01,  1.7518e-01,  4.8702e-01,  6.7108e-01,  1.5906e+00]],\n",
      "\n",
      "         [[-6.1889e-01, -4.3669e-01,  2.5930e-01, -3.4532e-01, -3.9075e-01],\n",
      "          [-2.3842e-01, -1.6864e+00, -1.1463e+00, -6.6913e-01, -1.3749e+00],\n",
      "          [ 1.9675e-01, -2.0826e+00,  4.0092e-01, -1.0830e+00, -1.0485e+00],\n",
      "          [ 5.1534e-01, -6.4022e-02,  4.1437e-01,  1.8068e-01, -6.2624e-01]]]]), tensor([[ 1.0475],\n",
      "        [-0.4126],\n",
      "        [-0.4771],\n",
      "        [ 0.1558],\n",
      "        [ 1.5194],\n",
      "        [ 0.9214],\n",
      "        [ 2.5311],\n",
      "        [ 1.2540],\n",
      "        [ 1.3915],\n",
      "        [ 1.9006],\n",
      "        [ 2.0471],\n",
      "        [-0.0114],\n",
      "        [ 0.6002],\n",
      "        [-0.5047],\n",
      "        [ 0.2726],\n",
      "        [-0.7669],\n",
      "        [ 0.4070],\n",
      "        [-0.4017],\n",
      "        [-1.5764],\n",
      "        [-1.0371],\n",
      "        [ 0.6931],\n",
      "        [ 0.3984],\n",
      "        [ 1.2353],\n",
      "        [-1.4238],\n",
      "        [-0.4155],\n",
      "        [ 0.3601],\n",
      "        [-0.7124],\n",
      "        [ 0.2116],\n",
      "        [ 0.2373],\n",
      "        [-2.0784],\n",
      "        [-0.1381],\n",
      "        [ 1.0703],\n",
      "        [-1.2375],\n",
      "        [-0.4871],\n",
      "        [-0.9992],\n",
      "        [ 1.1647],\n",
      "        [-0.4326],\n",
      "        [-0.3556],\n",
      "        [ 0.5533],\n",
      "        [-0.6602],\n",
      "        [ 1.1234],\n",
      "        [-0.6344],\n",
      "        [-2.0199],\n",
      "        [ 1.0377],\n",
      "        [-1.4148],\n",
      "        [ 0.8357],\n",
      "        [ 1.1696],\n",
      "        [-0.1994],\n",
      "        [-0.7760],\n",
      "        [ 0.0319],\n",
      "        [ 2.1148],\n",
      "        [-1.0877],\n",
      "        [ 0.1061],\n",
      "        [ 0.1833],\n",
      "        [ 1.3053],\n",
      "        [ 0.7028],\n",
      "        [-0.9786],\n",
      "        [-1.2275],\n",
      "        [ 0.3243],\n",
      "        [-0.2727],\n",
      "        [-0.8630],\n",
      "        [ 0.9035],\n",
      "        [-0.6607],\n",
      "        [ 1.1726],\n",
      "        [-0.9356],\n",
      "        [ 0.4048],\n",
      "        [-0.9340],\n",
      "        [-1.7635],\n",
      "        [-1.1382],\n",
      "        [-1.1728],\n",
      "        [-0.5952],\n",
      "        [ 1.6352],\n",
      "        [-1.3232],\n",
      "        [ 1.3731],\n",
      "        [ 0.5165],\n",
      "        [ 1.9854],\n",
      "        [-0.3791],\n",
      "        [-0.3813],\n",
      "        [-0.5303],\n",
      "        [-0.0922],\n",
      "        [ 0.8874],\n",
      "        [ 1.8371],\n",
      "        [-1.5238],\n",
      "        [-0.2378],\n",
      "        [-0.5124],\n",
      "        [-0.1959],\n",
      "        [ 0.8082],\n",
      "        [-0.6448],\n",
      "        [ 0.4154],\n",
      "        [ 2.4660],\n",
      "        [-1.4310],\n",
      "        [-0.0641],\n",
      "        [ 0.2522],\n",
      "        [ 0.5596],\n",
      "        [-1.5255],\n",
      "        [-0.1549],\n",
      "        [ 1.0426],\n",
      "        [ 0.3320],\n",
      "        [ 0.8652],\n",
      "        [ 1.1788],\n",
      "        [ 0.4106],\n",
      "        [ 1.3020],\n",
      "        [ 1.0191],\n",
      "        [-1.4508],\n",
      "        [-0.3878],\n",
      "        [ 1.0567],\n",
      "        [-0.1156],\n",
      "        [-2.5173],\n",
      "        [ 0.3626],\n",
      "        [ 1.5414],\n",
      "        [-0.1436],\n",
      "        [ 0.1811],\n",
      "        [-0.4931],\n",
      "        [-0.2298],\n",
      "        [-2.1906],\n",
      "        [ 0.1957],\n",
      "        [ 1.8576],\n",
      "        [ 2.1177],\n",
      "        [-0.1282],\n",
      "        [ 1.1342]])]\n",
      "[tensor([[[[ 6.1272e-01, -4.7549e-01, -4.3700e-02, -6.7117e-01, -3.9849e-01],\n",
      "          [-3.5940e-02, -1.4830e+00,  1.8498e+00,  3.5706e-01,  1.1349e+00],\n",
      "          [-8.0812e-01, -3.7952e-01,  7.0025e-01,  8.4454e-01, -5.4006e-01],\n",
      "          [ 7.4350e-01, -2.8672e-01,  1.0256e+00,  9.4589e-01, -1.7221e+00]],\n",
      "\n",
      "         [[-2.4623e+00,  7.9043e-01, -5.8958e-01,  1.6151e+00, -6.6184e-01],\n",
      "          [ 5.5516e-01, -6.2957e-01,  2.1895e-01,  8.6367e-01,  1.1302e+00],\n",
      "          [-1.7844e-01, -1.5195e+00,  2.2505e+00,  2.2756e+00,  7.9682e-01],\n",
      "          [ 3.6931e-01, -1.2735e+00,  1.2404e-01, -8.2943e-01,  1.1134e+00]],\n",
      "\n",
      "         [[ 1.1499e+00, -5.2047e-01,  1.5102e-01, -1.5696e+00,  2.4505e+00],\n",
      "          [ 4.6147e-01, -2.1152e+00, -1.3850e+00, -3.1577e-01, -6.4714e-01],\n",
      "          [-2.2692e-01,  3.7116e-01, -7.6878e-01, -2.1083e-01, -1.7386e+00],\n",
      "          [-7.6242e-01, -7.2089e-01, -8.6024e-01,  9.6756e-01, -1.8291e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8177e+00, -8.2624e-01,  4.9460e-01,  1.2324e+00,  6.5283e-01],\n",
      "          [-4.8232e-01, -5.5895e-01, -9.8175e-02, -9.3545e-01, -1.3362e+00],\n",
      "          [-4.9902e-01,  2.0755e-01, -3.7619e-01,  2.2857e+00,  4.1866e-01],\n",
      "          [-2.8900e-01, -4.2500e-01, -1.4486e+00,  4.2609e-01, -7.3261e-01]],\n",
      "\n",
      "         [[-2.2401e+00,  1.2473e+00, -3.6209e-01, -8.7259e-01, -3.1678e-01],\n",
      "          [-5.1860e-01,  2.0149e+00,  1.0660e+00, -3.2267e-01,  6.7179e-01],\n",
      "          [-1.0840e+00,  1.2635e+00, -6.2563e-02,  1.0934e+00, -4.5508e-01],\n",
      "          [ 2.6642e-01, -2.7450e-01,  4.1372e-01,  1.1811e+00,  6.9462e-02]],\n",
      "\n",
      "         [[-3.4671e-01,  7.6524e-01, -3.1688e+00, -2.1104e-01, -1.5846e-01],\n",
      "          [-6.7378e-01,  1.1763e+00,  1.5001e+00, -4.5579e-01,  7.6487e-01],\n",
      "          [ 2.3923e+00, -2.0695e-01,  6.1467e-01, -9.2425e-01,  8.8631e-01],\n",
      "          [-1.0490e+00,  4.2466e-02, -4.8133e-02, -1.8807e+00, -6.1065e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4195e-01,  1.5098e+00,  2.3656e-01, -5.5013e-01,  1.4430e+00],\n",
      "          [-2.5124e-01, -4.7657e-01, -1.0709e+00,  8.9781e-01, -8.1545e-01],\n",
      "          [ 2.6434e-01,  9.7903e-02,  5.7760e-01,  5.8345e-01,  7.2548e-02],\n",
      "          [ 1.6879e+00, -1.1095e+00,  2.6836e-01,  1.7074e+00,  8.1588e-01]],\n",
      "\n",
      "         [[-1.5226e+00,  3.9123e-01,  2.2602e+00, -1.2412e-01, -3.9368e-01],\n",
      "          [ 9.1100e-01,  7.2128e-01, -1.1285e+00, -8.7227e-01, -9.4465e-01],\n",
      "          [-6.6239e-01, -1.5667e-01,  2.2563e-01,  1.0356e-01, -1.9185e-01],\n",
      "          [ 6.1784e-01, -1.0776e-01,  8.7354e-03,  1.1926e-02,  3.2733e-01]],\n",
      "\n",
      "         [[ 2.6639e-01, -6.9846e-02,  1.7296e+00,  6.4346e-01,  1.2317e+00],\n",
      "          [-1.8547e+00, -7.9019e-01, -4.9890e-01, -1.8538e+00,  6.0061e-01],\n",
      "          [-1.0317e+00, -2.0443e-01, -1.5183e+00, -7.5327e-03, -5.7087e-03],\n",
      "          [-4.8235e-01,  8.0939e-01, -5.2657e-01, -7.7827e-01,  9.5237e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.1166e+00, -1.4114e+00, -8.9538e-01,  8.7154e-01,  3.1755e-01],\n",
      "          [ 2.0583e+00, -1.5293e+00, -2.0967e-01, -1.3582e+00, -8.9201e-02],\n",
      "          [ 6.3442e-01, -1.8426e+00,  6.6574e-01,  3.4938e-01,  9.9507e-01],\n",
      "          [ 6.4211e-01,  1.0807e+00, -8.7315e-01, -1.5470e+00,  1.0969e-01]],\n",
      "\n",
      "         [[-1.0532e+00,  1.1761e+00,  1.6409e-01, -9.0976e-01, -7.1205e-01],\n",
      "          [-1.2365e+00, -1.5972e+00, -8.9653e-01,  2.1760e-03, -6.5349e-01],\n",
      "          [ 1.1608e-01, -1.4684e+00,  1.4376e+00, -1.3205e+00,  1.3120e+00],\n",
      "          [-1.2004e-01,  2.0098e+00,  9.3731e-01, -9.3690e-01,  8.0321e-02]],\n",
      "\n",
      "         [[ 1.5966e+00,  9.0173e-01,  7.5337e-02, -2.2569e-01, -4.7498e-01],\n",
      "          [ 6.7078e-01, -7.7972e-01,  4.0642e-01,  1.2489e+00, -1.4642e-01],\n",
      "          [ 6.0360e-01,  2.4094e-02, -5.7441e-01, -6.0628e-02, -1.8840e-01],\n",
      "          [-1.3073e+00, -3.0667e+00, -3.7150e-01,  7.4854e-01,  8.1936e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3485e+00, -3.8312e-01,  5.1563e-01, -2.9002e-01, -3.7645e-02],\n",
      "          [-3.0099e-01,  1.0908e-01,  6.8698e-01,  1.5455e+00, -9.6137e-01],\n",
      "          [ 1.3037e+00,  1.5960e+00, -2.8719e-02,  3.8317e-01, -1.8313e+00],\n",
      "          [ 6.8566e-01, -7.7539e-02,  6.8112e-01,  5.6786e-01,  9.8776e-01]],\n",
      "\n",
      "         [[-8.2554e-01,  8.7310e-01,  8.6371e-01,  6.4382e-01,  5.7720e-02],\n",
      "          [-2.0970e+00,  6.9601e-01,  8.5333e-01, -6.2642e-02,  7.7408e-01],\n",
      "          [ 8.9768e-01, -1.1929e+00,  2.4068e-01, -1.9433e-02,  6.0317e-01],\n",
      "          [ 8.2712e-01,  2.1033e+00, -3.6699e-01, -3.2224e-01, -5.2272e-02]],\n",
      "\n",
      "         [[ 6.3393e-01,  7.1104e-01,  1.8280e-02, -1.9453e-01, -2.1632e-01],\n",
      "          [ 5.5723e-01, -3.9738e-01,  5.2028e-01, -1.0669e+00,  5.2034e-01],\n",
      "          [ 4.8320e-01,  2.8969e-01,  2.1855e-02,  2.3415e-01,  3.8303e-01],\n",
      "          [ 1.2130e+00, -4.8092e-01,  5.4218e-01, -3.6053e-01,  2.4652e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6380e-01, -8.8763e-02, -2.1369e+00,  1.6728e-01, -8.2324e-01],\n",
      "          [-1.2921e+00,  9.7224e-01,  1.4640e+00,  2.1106e+00,  1.1499e+00],\n",
      "          [ 2.0955e+00, -6.3494e-01,  6.4248e-01, -5.6672e-01, -2.7282e-01],\n",
      "          [ 1.4768e+00, -5.9815e-02,  1.4815e+00,  2.1155e+00,  9.0784e-01]],\n",
      "\n",
      "         [[-2.0341e+00,  4.0987e-01, -1.0567e+00,  8.0699e-01, -1.9654e-01],\n",
      "          [ 4.5190e-01,  6.9016e-01,  3.4330e-01,  8.8147e-02, -6.0155e-01],\n",
      "          [ 1.6413e+00,  7.5949e-01, -1.5607e+00, -8.6762e-01,  7.1216e-01],\n",
      "          [-2.7266e-01, -1.2823e+00,  1.1718e+00,  5.2334e-01, -1.0281e+00]],\n",
      "\n",
      "         [[ 1.4393e+00,  4.3968e-01,  3.2014e-01,  4.1884e-01,  1.3991e+00],\n",
      "          [ 1.1557e+00, -9.7858e-01, -3.7081e-01,  5.3193e-01,  5.4337e-01],\n",
      "          [ 1.0452e+00,  2.0780e-01,  2.5396e-02, -2.2513e+00, -1.2956e+00],\n",
      "          [ 1.3136e-01, -1.6284e+00, -7.8582e-01, -2.1578e+00, -1.0265e-01]]]]), tensor([[-0.8372],\n",
      "        [-0.6087],\n",
      "        [ 0.5670],\n",
      "        [-0.7664],\n",
      "        [-1.3387],\n",
      "        [-0.8262],\n",
      "        [-2.0267],\n",
      "        [-0.3420],\n",
      "        [ 1.5615],\n",
      "        [ 0.6463],\n",
      "        [ 0.0320],\n",
      "        [ 0.7537],\n",
      "        [ 0.4014],\n",
      "        [ 0.7678],\n",
      "        [ 0.4489],\n",
      "        [-1.5062],\n",
      "        [-0.5819],\n",
      "        [-0.1184],\n",
      "        [-1.2036],\n",
      "        [ 1.5232],\n",
      "        [ 1.0630],\n",
      "        [ 0.0612],\n",
      "        [-0.1422],\n",
      "        [-1.7449],\n",
      "        [-0.7032],\n",
      "        [ 0.2152],\n",
      "        [ 1.5456],\n",
      "        [ 0.1187],\n",
      "        [-0.1160],\n",
      "        [-1.4281],\n",
      "        [ 0.9471],\n",
      "        [ 1.7472],\n",
      "        [-0.4160],\n",
      "        [ 0.0711],\n",
      "        [-0.3057],\n",
      "        [ 0.2640],\n",
      "        [-0.2360],\n",
      "        [ 0.4420],\n",
      "        [-0.5041],\n",
      "        [-0.1843],\n",
      "        [ 0.6314],\n",
      "        [ 1.6519],\n",
      "        [-0.2711],\n",
      "        [-0.4191],\n",
      "        [-1.5557],\n",
      "        [-0.4079],\n",
      "        [-1.0438],\n",
      "        [-0.8492],\n",
      "        [-0.1813],\n",
      "        [ 0.2559],\n",
      "        [ 0.1091],\n",
      "        [ 0.3501],\n",
      "        [-0.5018],\n",
      "        [ 0.4894],\n",
      "        [ 1.2256],\n",
      "        [-0.1169],\n",
      "        [ 0.8098],\n",
      "        [-0.1429],\n",
      "        [ 0.7019],\n",
      "        [-0.3035],\n",
      "        [ 0.6332],\n",
      "        [ 1.6574],\n",
      "        [-1.1813],\n",
      "        [-1.2948],\n",
      "        [ 0.3633],\n",
      "        [-0.4615],\n",
      "        [ 0.5139],\n",
      "        [-0.8699],\n",
      "        [-0.4078],\n",
      "        [ 0.2860],\n",
      "        [-1.0000],\n",
      "        [ 0.7320],\n",
      "        [ 0.5206],\n",
      "        [ 0.2048],\n",
      "        [-0.6831],\n",
      "        [ 0.1843],\n",
      "        [-0.6886],\n",
      "        [-1.7188],\n",
      "        [-0.9084],\n",
      "        [ 0.1281],\n",
      "        [ 0.6128],\n",
      "        [ 0.9347],\n",
      "        [-1.4260],\n",
      "        [ 0.4532],\n",
      "        [-1.3176],\n",
      "        [-0.5491],\n",
      "        [-0.7238],\n",
      "        [-0.1276],\n",
      "        [-1.5097],\n",
      "        [ 0.5193],\n",
      "        [ 0.8605],\n",
      "        [-0.7354],\n",
      "        [ 1.6511],\n",
      "        [ 0.9421],\n",
      "        [-0.4663],\n",
      "        [-0.1970],\n",
      "        [ 0.2344],\n",
      "        [ 0.1480],\n",
      "        [-2.2961],\n",
      "        [ 0.1843],\n",
      "        [-0.7250],\n",
      "        [ 1.2807],\n",
      "        [-0.1190],\n",
      "        [ 1.0637],\n",
      "        [ 0.8845],\n",
      "        [ 0.0041],\n",
      "        [-0.6367],\n",
      "        [ 2.1515],\n",
      "        [-1.3177],\n",
      "        [ 0.1781],\n",
      "        [ 2.0246],\n",
      "        [-1.4731],\n",
      "        [-0.1201],\n",
      "        [-0.5409],\n",
      "        [ 0.8455],\n",
      "        [ 0.4000],\n",
      "        [-0.7804],\n",
      "        [-1.1135],\n",
      "        [ 0.9475],\n",
      "        [ 0.8643]])]\n",
      "[tensor([[[[-1.0029e+00,  1.2056e+00,  1.3688e+00, -2.1212e-01, -2.5571e-01],\n",
      "          [-7.3158e-01,  4.1310e-01, -8.6409e-01,  9.3749e-01, -6.7163e-01],\n",
      "          [ 4.9593e-01, -1.6912e+00, -1.9813e+00, -2.1804e+00,  4.7268e-01],\n",
      "          [-2.1912e-01, -2.4594e+00,  1.4101e+00, -1.4732e+00, -1.0086e+00]],\n",
      "\n",
      "         [[ 1.8950e-01, -6.2945e-01, -6.7834e-01, -7.3111e-01, -2.6724e+00],\n",
      "          [-7.4426e-01, -6.3586e-02,  1.0681e+00, -5.9385e-01, -5.9217e-01],\n",
      "          [-3.4018e-01,  1.0743e+00, -9.7549e-02,  3.1573e-01, -1.3144e+00],\n",
      "          [-8.2862e-01,  6.2174e-01,  1.2704e-01,  1.5215e+00,  3.0823e-01]],\n",
      "\n",
      "         [[ 1.1847e+00, -9.2031e-01, -8.4590e-02,  1.4395e-01, -4.1921e-01],\n",
      "          [-2.8753e-02, -2.0161e-01,  6.5325e-01, -1.3319e-01, -1.0959e+00],\n",
      "          [ 4.9235e-01,  1.1535e+00, -5.2738e-01,  2.0224e-01,  2.0542e+00],\n",
      "          [-1.6541e+00,  7.3324e-01, -2.0506e-01, -1.0635e-01, -1.1525e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1833e-01,  5.3392e-01,  4.5137e-01, -6.2970e-01,  5.9392e-01],\n",
      "          [ 2.5368e-02, -7.4354e-01, -7.4514e-01, -1.2143e+00,  9.1235e-01],\n",
      "          [ 1.8408e-02,  4.0375e-01, -3.1385e-01,  3.0658e-01, -1.0063e+00],\n",
      "          [-7.6874e-02, -7.4444e-01,  2.2934e-01, -7.6159e-02, -2.7159e+00]],\n",
      "\n",
      "         [[-7.5827e-01,  7.6108e-01, -5.1562e-01,  1.2077e+00,  5.5172e-01],\n",
      "          [ 5.2108e-01,  1.7180e+00,  1.6007e-01, -1.0025e+00,  7.4162e-01],\n",
      "          [ 4.4589e-01,  1.5495e+00,  2.0442e-02, -1.0543e+00,  9.7473e-01],\n",
      "          [-4.7404e-01,  8.1413e-01,  1.0724e-01,  3.0160e-01,  5.2289e-01]],\n",
      "\n",
      "         [[ 1.2550e-01, -4.5073e-01,  7.3050e-01, -1.3135e+00,  1.0716e-01],\n",
      "          [-9.2885e-02, -1.4970e+00,  1.5237e+00,  5.0380e-01,  8.8633e-01],\n",
      "          [ 9.3483e-01,  4.2585e-01, -6.6806e-01, -5.5891e-01,  5.3189e-01],\n",
      "          [-2.0063e+00,  6.1807e-01,  1.4871e+00,  3.8951e-01, -5.2390e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3212e+00, -2.6994e-01, -1.0356e+00, -9.6379e-01, -1.5266e+00],\n",
      "          [-7.9065e-01,  1.6272e+00, -4.8115e-01,  2.8901e-01,  7.3745e-01],\n",
      "          [ 1.1288e-01,  3.4709e-01,  2.3575e+00,  5.0961e-01, -1.2768e-01],\n",
      "          [-1.7942e+00,  1.3468e+00, -5.5696e-02, -2.3451e+00,  1.0020e+00]],\n",
      "\n",
      "         [[ 4.0669e-01, -6.5046e-01, -2.2092e+00, -2.0083e-04, -1.0803e+00],\n",
      "          [ 6.1195e-01, -2.0068e+00, -5.4108e-01,  4.1355e-01, -6.9763e-01],\n",
      "          [-1.0852e-01, -1.1571e+00,  1.0871e+00, -7.2853e-01,  2.0402e+00],\n",
      "          [ 1.2049e+00,  2.0524e-01,  1.9673e-01,  1.7048e+00,  6.5610e-01]],\n",
      "\n",
      "         [[-9.2394e-01, -8.0219e-01,  7.4636e-01, -1.6317e+00,  2.4498e-01],\n",
      "          [-9.3674e-01, -6.2772e-01,  1.3881e+00,  2.0555e-01, -2.0828e+00],\n",
      "          [-9.6567e-01,  4.8762e-01, -1.5349e+00, -1.2122e+00, -7.7701e-01],\n",
      "          [-4.8901e-01, -3.0343e-01, -1.9894e+00, -4.0334e-01,  2.8564e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.1363e-01, -1.0930e+00,  5.0521e-01,  3.5873e-01, -9.8002e-01],\n",
      "          [-7.4497e-01,  2.7856e-01, -3.3939e-01,  5.4769e-02,  9.5250e-01],\n",
      "          [-1.3139e+00, -7.6777e-01, -1.5605e+00,  9.0268e-01, -4.1935e-01],\n",
      "          [-1.5870e-01,  1.1612e-01,  1.5564e+00, -8.8541e-01,  2.6422e-01]],\n",
      "\n",
      "         [[ 3.6514e-02, -1.3754e+00, -7.9068e-02,  1.5882e+00, -3.6170e-01],\n",
      "          [-1.7126e+00, -4.1753e-01,  7.2301e-01, -8.3347e-01, -1.6665e-01],\n",
      "          [ 8.6709e-01, -9.1297e-01,  9.7619e-01,  1.4978e+00, -3.8184e-01],\n",
      "          [ 8.1514e-01,  5.4580e-01,  1.2379e+00, -9.4806e-01, -5.1109e-02]],\n",
      "\n",
      "         [[-4.9126e-01,  9.4726e-01,  2.7178e-01, -7.2885e-02, -3.5849e-01],\n",
      "          [-1.3334e+00, -1.2062e+00, -6.0794e-01,  1.2000e+00,  3.5149e-01],\n",
      "          [-5.8298e-01, -9.5009e-01,  1.0879e+00,  1.1987e+00, -2.2532e-01],\n",
      "          [ 1.3393e+00,  6.9245e-01, -1.5173e+00, -1.6743e+00, -4.2907e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6155e-01, -4.4752e-01,  1.1529e-01, -1.3705e-01, -1.8523e+00],\n",
      "          [-1.6628e-01,  2.1491e-01,  4.1774e-02,  5.1432e-01,  1.1959e-01],\n",
      "          [ 1.2633e+00,  8.9006e-01, -1.0688e-01, -6.6207e-01,  1.4374e+00],\n",
      "          [ 1.1993e+00, -5.9281e-01, -7.9963e-01, -9.8375e-01,  2.2474e-01]],\n",
      "\n",
      "         [[ 6.7862e-01, -8.5379e-01,  1.2398e-01, -1.6651e-01,  3.5340e-01],\n",
      "          [-2.7278e-02, -2.2447e-01, -1.2317e+00,  5.2201e-02,  2.9212e-01],\n",
      "          [-4.5153e-01, -1.2962e+00, -9.8488e-01, -1.1795e+00, -2.1026e+00],\n",
      "          [-5.7915e-01,  7.6992e-01,  7.8270e-01, -1.8569e-02, -9.9128e-01]],\n",
      "\n",
      "         [[ 8.1479e-01, -9.4730e-02,  5.6182e-01,  5.2387e-01, -5.6749e-01],\n",
      "          [-8.3309e-01, -6.1412e-01,  2.2992e-01, -1.5106e+00,  1.7937e+00],\n",
      "          [-8.5733e-01, -1.2170e+00, -1.1181e-01, -5.3329e-01,  4.4257e-01],\n",
      "          [-1.3246e+00,  8.6349e-01, -4.6922e-01,  1.5677e+00, -8.5436e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.2714e-01,  9.3628e-01, -1.3126e+00, -7.9707e-01,  4.7286e-01],\n",
      "          [ 4.9184e-01, -1.0786e+00, -3.3963e-02,  2.2898e-02, -1.4426e+00],\n",
      "          [ 5.3702e-01,  3.7616e-01, -3.7645e-01,  2.5081e-01,  7.1057e-01],\n",
      "          [ 1.4768e-01,  1.9415e-01, -4.1661e-01, -9.1539e-01,  1.1415e+00]],\n",
      "\n",
      "         [[-5.3904e-01,  3.6441e-01, -6.0888e-02,  1.4303e+00, -2.8400e-01],\n",
      "          [-1.3040e+00, -1.3132e+00,  2.9203e-01, -7.7871e-01,  1.4314e+00],\n",
      "          [ 1.3845e+00, -1.6264e-01, -1.2068e+00, -8.6933e-02,  1.2161e+00],\n",
      "          [-1.2347e+00,  1.3981e-01, -5.9245e-01,  1.1001e+00, -2.6276e-01]],\n",
      "\n",
      "         [[ 1.9563e+00,  1.4125e-01,  1.8777e+00, -7.0158e-03, -3.3094e-01],\n",
      "          [ 1.5259e+00,  1.1097e+00,  1.1653e+00,  6.5823e-01, -9.5917e-01],\n",
      "          [ 1.1592e+00, -8.9423e-01,  9.5185e-01, -1.0719e+00,  5.0960e-02],\n",
      "          [ 6.6764e-02, -2.4166e+00,  1.6734e+00,  8.9247e-01,  3.1513e-01]]]]), tensor([[ 6.4832e-01],\n",
      "        [ 2.4760e+00],\n",
      "        [-1.8988e+00],\n",
      "        [ 1.4824e+00],\n",
      "        [-3.1434e-01],\n",
      "        [-3.3212e-01],\n",
      "        [ 5.3539e-01],\n",
      "        [ 9.6267e-01],\n",
      "        [-1.3495e+00],\n",
      "        [ 5.0776e-02],\n",
      "        [-2.2475e-01],\n",
      "        [ 1.1230e+00],\n",
      "        [-7.0841e-01],\n",
      "        [ 1.1804e+00],\n",
      "        [-3.1081e-02],\n",
      "        [ 2.0041e-02],\n",
      "        [-6.9518e-01],\n",
      "        [ 1.9666e-01],\n",
      "        [ 5.9404e-04],\n",
      "        [ 1.3860e+00],\n",
      "        [ 1.0795e+00],\n",
      "        [ 1.2296e+00],\n",
      "        [-1.7044e-01],\n",
      "        [ 5.0965e-01],\n",
      "        [ 3.9876e-01],\n",
      "        [-7.5283e-01],\n",
      "        [-1.2280e+00],\n",
      "        [-2.7642e-01],\n",
      "        [ 1.0194e-01],\n",
      "        [-3.5852e-01],\n",
      "        [ 1.4475e+00],\n",
      "        [-1.3001e+00],\n",
      "        [ 1.0374e-01],\n",
      "        [-7.1899e-01],\n",
      "        [ 3.3886e-01],\n",
      "        [-4.9029e-01],\n",
      "        [-3.5969e-01],\n",
      "        [ 1.2787e-01],\n",
      "        [ 2.1017e+00],\n",
      "        [-8.7413e-01],\n",
      "        [-2.8776e+00],\n",
      "        [-9.5070e-01],\n",
      "        [ 6.5859e-02],\n",
      "        [ 1.3429e+00],\n",
      "        [ 8.8871e-01],\n",
      "        [-4.3501e-01],\n",
      "        [-3.9396e-01],\n",
      "        [-4.6259e-01],\n",
      "        [ 6.0666e-01],\n",
      "        [-2.0654e+00],\n",
      "        [-7.9677e-01],\n",
      "        [-1.1506e+00],\n",
      "        [ 1.3955e-01],\n",
      "        [-6.1898e-01],\n",
      "        [-3.4932e-02],\n",
      "        [ 9.1176e-01],\n",
      "        [ 9.4511e-01],\n",
      "        [-2.4072e-01],\n",
      "        [ 4.9101e-01],\n",
      "        [ 7.7760e-01],\n",
      "        [-1.2995e+00],\n",
      "        [-1.1454e+00],\n",
      "        [ 6.4393e-02],\n",
      "        [ 2.0006e-01],\n",
      "        [ 1.8769e+00],\n",
      "        [ 9.7511e-01],\n",
      "        [ 1.2380e+00],\n",
      "        [-9.3343e-02],\n",
      "        [-1.4782e-01],\n",
      "        [ 3.0057e-01],\n",
      "        [ 7.1070e-01],\n",
      "        [-5.2536e-01],\n",
      "        [-7.4131e-01],\n",
      "        [-1.8817e-01],\n",
      "        [ 1.1569e-01],\n",
      "        [-6.2501e-01],\n",
      "        [-5.4279e-01],\n",
      "        [-4.3249e-01],\n",
      "        [ 1.0938e+00],\n",
      "        [ 1.0338e-01],\n",
      "        [-1.3758e+00],\n",
      "        [ 9.3761e-01],\n",
      "        [ 1.4458e-01],\n",
      "        [ 3.6389e-02],\n",
      "        [ 1.3694e+00],\n",
      "        [-1.5528e-01],\n",
      "        [ 6.8392e-01],\n",
      "        [ 1.2044e+00],\n",
      "        [-9.6979e-01],\n",
      "        [ 1.0896e+00],\n",
      "        [-4.3055e-01],\n",
      "        [ 3.8058e-01],\n",
      "        [-1.6740e-02],\n",
      "        [ 2.5904e+00],\n",
      "        [ 6.5300e-01],\n",
      "        [ 3.5048e-01],\n",
      "        [ 1.0413e+00],\n",
      "        [-3.7063e-01],\n",
      "        [ 1.5731e+00],\n",
      "        [-7.6734e-01],\n",
      "        [ 1.0753e+00],\n",
      "        [-8.1262e-01],\n",
      "        [-1.2161e+00],\n",
      "        [ 4.5471e-01],\n",
      "        [ 4.8638e-01],\n",
      "        [ 9.4133e-01],\n",
      "        [ 6.6273e-01],\n",
      "        [ 2.5901e-01],\n",
      "        [-2.3446e+00],\n",
      "        [-2.8110e-01],\n",
      "        [ 5.0490e-01],\n",
      "        [-7.7074e-02],\n",
      "        [-1.9469e-01],\n",
      "        [-8.2350e-02],\n",
      "        [ 2.0049e-01],\n",
      "        [-8.8562e-04],\n",
      "        [ 1.9726e+00],\n",
      "        [ 8.1439e-02],\n",
      "        [-2.0653e-01],\n",
      "        [ 2.9056e-01]])]\n",
      "[tensor([[[[ 2.2821e-01,  8.0406e-01, -1.9289e-01,  2.0320e+00,  1.0106e+00],\n",
      "          [ 1.1037e+00, -7.0859e-01,  3.2794e-01, -1.2287e+00,  1.2146e+00],\n",
      "          [-6.3396e-01,  1.0846e+00, -4.5967e-01, -1.0970e+00, -4.5391e-01],\n",
      "          [-1.9351e-01,  6.1379e-01, -1.0860e+00, -5.4659e-01, -3.1706e-01]],\n",
      "\n",
      "         [[ 5.1215e-01, -3.5700e-01, -7.0461e-01,  9.0804e-02, -4.4230e-02],\n",
      "          [-9.6407e-01, -1.3818e+00, -4.6245e-01, -8.8908e-01,  9.7110e-01],\n",
      "          [-8.4005e-01, -8.6322e-01,  1.2962e+00, -3.7319e-01,  1.4869e-01],\n",
      "          [ 1.0317e+00,  6.5009e-01, -5.0541e-01, -6.7146e-02,  2.1268e+00]],\n",
      "\n",
      "         [[-1.2687e+00, -1.4629e+00,  1.5393e+00, -9.2404e-02,  1.6328e+00],\n",
      "          [ 2.7741e-01,  8.9704e-01, -8.5849e-01, -2.4865e-02,  1.4984e+00],\n",
      "          [ 2.5553e-01, -1.1133e+00, -8.2925e-01,  6.7524e-01,  1.1175e+00],\n",
      "          [-3.2750e-01,  4.7423e-01, -2.9663e-01, -9.8344e-01,  2.7432e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1859e+00,  2.0706e+00,  4.4318e-01, -1.1822e+00, -7.6530e-01],\n",
      "          [-1.8175e+00,  1.8829e-01,  2.1155e-01,  1.8536e+00,  4.2297e+00],\n",
      "          [ 1.8228e-01,  1.1395e+00, -7.5711e-01, -1.0448e+00, -7.6347e-01],\n",
      "          [-2.1438e+00, -1.4005e-02,  3.2505e-03,  2.0391e-01,  1.2509e+00]],\n",
      "\n",
      "         [[ 1.0318e+00, -1.1375e-01, -2.4683e+00,  1.0063e+00, -2.1891e-01],\n",
      "          [-2.4957e+00,  4.5960e-01, -1.0236e+00,  7.2530e-01, -1.1308e+00],\n",
      "          [ 6.4564e-01, -8.0730e-01, -2.3839e+00, -8.1989e-01,  9.2376e-02],\n",
      "          [ 1.5979e+00, -1.0335e+00, -9.5096e-02, -6.1244e-01, -1.3810e+00]],\n",
      "\n",
      "         [[-8.8214e-01,  1.2477e+00, -3.7459e-01,  6.5908e-01, -1.8227e-01],\n",
      "          [ 6.2545e-01,  7.7912e-01, -2.7021e-01, -1.1522e+00, -4.5098e-01],\n",
      "          [ 1.8153e+00,  2.6634e+00, -1.1097e+00,  1.4731e+00, -2.1326e-01],\n",
      "          [ 1.2621e+00,  8.0319e-02,  7.3999e-01, -8.4422e-01, -9.4330e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.3654e-01,  4.2039e-01,  8.9098e-02,  1.5253e+00, -1.1020e+00],\n",
      "          [ 2.1571e+00,  1.0878e+00,  5.8356e-01, -9.4070e-01,  1.7576e+00],\n",
      "          [-4.9808e-01, -1.8816e+00,  2.8025e-01,  1.4677e+00, -9.5122e-01],\n",
      "          [-1.1138e+00, -5.9154e-01,  6.9239e-01, -8.9124e-01,  2.1859e+00]],\n",
      "\n",
      "         [[ 1.2317e+00,  9.6830e-01,  8.2611e-01, -1.1362e+00, -3.5335e-01],\n",
      "          [ 3.5635e-01,  3.5419e-01, -3.7676e-01, -8.7177e-01, -3.6724e-01],\n",
      "          [-1.8082e+00, -1.2786e+00, -2.0479e+00,  8.1784e-02,  5.4470e-01],\n",
      "          [ 2.2444e+00, -1.7936e+00, -4.1218e-02, -3.9286e-01, -1.0654e-01]],\n",
      "\n",
      "         [[-2.9369e-01, -5.7323e-01, -1.1507e+00, -2.3647e+00,  1.1797e+00],\n",
      "          [-9.1580e-01, -1.6259e-01, -2.5378e+00, -1.3560e+00, -8.6202e-01],\n",
      "          [ 1.0920e+00,  1.8347e+00, -7.8189e-01,  9.9692e-02,  4.4808e-01],\n",
      "          [ 8.7481e-01,  9.5632e-01,  1.0987e-01, -3.8384e-01,  2.3867e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.4284e-01, -9.8248e-01,  2.6366e-01, -5.8111e-01, -5.0754e-01],\n",
      "          [ 1.5498e+00,  5.9207e-01, -9.4390e-01, -5.8303e-01, -5.9627e-01],\n",
      "          [ 3.0154e-01,  9.6736e-01,  2.5559e-02,  1.0119e+00,  6.6902e-01],\n",
      "          [-4.6794e-01, -2.3960e-01, -5.6191e-01,  2.2621e+00, -1.4681e+00]],\n",
      "\n",
      "         [[-2.8497e-01, -3.8420e-02,  1.6814e+00, -8.1976e-01, -6.0231e-01],\n",
      "          [-3.0764e-01,  4.4056e-01,  8.4107e-01,  1.3847e-01, -4.2392e-01],\n",
      "          [ 1.0465e+00,  1.1302e+00,  2.8576e-01,  9.3276e-01, -1.6243e+00],\n",
      "          [ 1.1393e+00,  1.5682e+00, -4.3882e-01,  8.7649e-01, -5.9016e-01]],\n",
      "\n",
      "         [[ 5.4718e-01,  1.4337e+00, -4.2785e-01,  1.2311e+00, -7.4220e-01],\n",
      "          [-1.9676e-01,  6.7949e-01,  2.5557e-01, -1.9073e+00, -1.7791e+00],\n",
      "          [-5.1821e-01,  1.6327e+00,  8.3871e-02, -1.5256e+00,  5.2522e-01],\n",
      "          [-3.8321e-01,  4.1429e-01,  1.8176e-01,  1.1377e+00, -9.3793e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.3411e-01, -4.0773e-01, -8.4630e-01,  1.6457e+00, -6.2748e-01],\n",
      "          [-3.9765e-01, -1.6114e+00,  7.7682e-01, -4.5416e-01,  3.2924e-01],\n",
      "          [-8.5082e-03, -3.7414e-01,  8.8025e-01, -1.1905e+00,  5.2023e-01],\n",
      "          [ 7.8806e-01, -4.2128e-01, -5.0190e-02,  8.4606e-01,  1.9809e-02]],\n",
      "\n",
      "         [[-1.5974e+00,  5.3940e-01,  1.5549e+00, -1.5783e+00,  1.2054e+00],\n",
      "          [-6.2511e-01, -6.8926e-01, -4.4489e-01, -6.5166e-01,  4.2201e-01],\n",
      "          [ 3.1199e-01,  5.2959e-02, -1.5905e+00,  8.4446e-01, -8.6857e-01],\n",
      "          [ 1.8434e+00, -7.9866e-01,  1.7688e-01, -1.3047e-01,  1.1961e+00]],\n",
      "\n",
      "         [[ 4.6101e-01,  4.5048e-01,  1.5902e+00, -2.4085e-01, -1.3575e-01],\n",
      "          [-1.4242e+00, -7.6437e-01, -7.5740e-01, -1.2902e+00,  1.2318e+00],\n",
      "          [-1.5066e+00, -1.0248e+00, -1.8325e+00,  6.1289e-01, -8.5840e-01],\n",
      "          [-7.8336e-01, -2.4463e-01,  1.7775e+00,  1.9016e+00, -2.4059e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0603e-01,  1.9593e+00,  1.6453e-01,  6.7840e-01, -1.4201e+00],\n",
      "          [ 9.3404e-01, -1.3481e+00,  5.0932e-01,  1.6160e+00,  3.0104e-01],\n",
      "          [-4.9350e-01,  3.8870e-01, -9.6207e-01, -2.3220e-01, -1.8165e-01],\n",
      "          [-2.7422e-01, -3.0188e-01,  2.4415e+00,  8.1160e-01, -1.1666e+00]],\n",
      "\n",
      "         [[ 8.0046e-01,  2.1387e-02, -9.9385e-02,  4.4552e-01,  1.1495e-01],\n",
      "          [ 5.9291e-01, -3.0401e-01,  9.7734e-01, -1.2101e+00,  1.1842e-01],\n",
      "          [-9.3435e-01, -5.9794e-01,  9.6701e-01,  6.8227e-01, -8.0157e-01],\n",
      "          [-6.5174e-01, -3.6419e-01, -1.3902e-01, -9.1767e-01,  1.3663e+00]],\n",
      "\n",
      "         [[ 1.3012e+00,  1.5780e+00, -1.3517e+00,  2.3367e+00,  7.2321e-01],\n",
      "          [ 1.8664e+00,  9.1403e-01, -8.6923e-01,  1.5063e+00,  8.6832e-01],\n",
      "          [-1.0112e+00, -1.2446e-01,  1.0380e+00,  1.3716e+00,  1.9343e-01],\n",
      "          [ 1.2176e+00,  5.0644e-01, -1.0937e+00, -8.4331e-02, -9.6963e-01]]]]), tensor([[-1.9426],\n",
      "        [ 0.5732],\n",
      "        [ 1.1991],\n",
      "        [-0.6885],\n",
      "        [-0.4599],\n",
      "        [-0.3098],\n",
      "        [-1.3160],\n",
      "        [-0.9286],\n",
      "        [-0.0144],\n",
      "        [-0.7060],\n",
      "        [ 0.4765],\n",
      "        [ 0.1686],\n",
      "        [ 0.6896],\n",
      "        [ 0.5890],\n",
      "        [-1.0065],\n",
      "        [ 0.3864],\n",
      "        [-1.2097],\n",
      "        [ 0.0704],\n",
      "        [ 0.7644],\n",
      "        [-0.0263],\n",
      "        [-0.5262],\n",
      "        [-0.7871],\n",
      "        [-0.5062],\n",
      "        [ 0.4250],\n",
      "        [-0.0897],\n",
      "        [ 0.8854],\n",
      "        [-0.5965],\n",
      "        [-0.7731],\n",
      "        [ 3.0149],\n",
      "        [-0.2046],\n",
      "        [-0.0676],\n",
      "        [-1.2438],\n",
      "        [-0.3812],\n",
      "        [-0.6835],\n",
      "        [-0.0738],\n",
      "        [ 0.3804],\n",
      "        [-2.0312],\n",
      "        [-1.3531],\n",
      "        [-0.9712],\n",
      "        [ 0.1109],\n",
      "        [ 1.4577],\n",
      "        [ 0.4879],\n",
      "        [-0.9613],\n",
      "        [ 0.5832],\n",
      "        [ 1.1624],\n",
      "        [-1.2271],\n",
      "        [ 0.6195],\n",
      "        [-0.9049],\n",
      "        [ 1.3619],\n",
      "        [ 0.6267],\n",
      "        [-1.2465],\n",
      "        [-0.6399],\n",
      "        [-0.9931],\n",
      "        [ 0.4047],\n",
      "        [-1.3898],\n",
      "        [-1.1122],\n",
      "        [-1.0711],\n",
      "        [-0.8036],\n",
      "        [-1.0623],\n",
      "        [-1.7516],\n",
      "        [-0.1993],\n",
      "        [-0.1049],\n",
      "        [-2.6138],\n",
      "        [ 0.1863],\n",
      "        [-1.3197],\n",
      "        [-1.3664],\n",
      "        [-0.0545],\n",
      "        [ 0.0751],\n",
      "        [ 0.1897],\n",
      "        [-1.1568],\n",
      "        [ 0.7356],\n",
      "        [ 0.1048],\n",
      "        [-0.9925],\n",
      "        [-1.9937],\n",
      "        [ 0.3411],\n",
      "        [ 0.8697],\n",
      "        [ 0.9320],\n",
      "        [-0.0678],\n",
      "        [-0.0326],\n",
      "        [-0.6797],\n",
      "        [-0.9259],\n",
      "        [ 0.5063],\n",
      "        [-1.4065],\n",
      "        [ 0.6579],\n",
      "        [-2.9688],\n",
      "        [ 1.2064],\n",
      "        [ 0.8331],\n",
      "        [-1.3833],\n",
      "        [ 0.1809],\n",
      "        [-0.3601],\n",
      "        [ 1.4748],\n",
      "        [ 0.5141],\n",
      "        [ 0.8463],\n",
      "        [-0.0172],\n",
      "        [ 0.1208],\n",
      "        [-0.0463],\n",
      "        [ 0.8093],\n",
      "        [-0.3592],\n",
      "        [-0.3131],\n",
      "        [ 0.4655],\n",
      "        [ 0.0194],\n",
      "        [ 0.0641],\n",
      "        [ 0.8710],\n",
      "        [ 0.1997],\n",
      "        [ 0.1753],\n",
      "        [-0.2232],\n",
      "        [-0.3450],\n",
      "        [-0.9469],\n",
      "        [ 1.1067],\n",
      "        [ 1.9014],\n",
      "        [ 0.2034],\n",
      "        [ 0.1929],\n",
      "        [-0.0244],\n",
      "        [-1.1268],\n",
      "        [ 0.6836],\n",
      "        [ 0.4422],\n",
      "        [ 0.0336],\n",
      "        [ 1.0940],\n",
      "        [-1.0594],\n",
      "        [-2.7349]])]\n"
     ]
    }
   ],
   "source": [
    "dataset =  DataLoader(data,\n",
    "           batch_size= bs,  # 抽样的大小\n",
    "           shuffle=True,   # 是否打乱抽样\n",
    "            drop_last=True  # 是否舍弃最后一个batch（无法除今的部分） 一般都是False\n",
    "            )\n",
    "\n",
    "\n",
    "#查看一下生成的对象\n",
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回一共有多少个batch\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回一共有多少个样本\n",
    "len(dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1839,  0.9627,  1.4169, -0.5208, -0.0273],\n",
       "         [-0.0235, -0.4743,  0.7232,  0.1129, -0.9538],\n",
       "         [ 0.6910, -1.3103,  0.2457,  0.4946,  0.1170],\n",
       "         [-0.3008, -0.7154,  0.8117,  0.7465, -0.4695]],\n",
       "\n",
       "        [[ 0.0158, -0.0928,  0.0184, -0.3890, -0.3316],\n",
       "         [ 0.8901,  0.6421, -0.8500, -0.3790, -0.8492],\n",
       "         [-0.4432, -0.6814,  0.5305, -1.1311,  0.9367],\n",
       "         [-0.4199, -1.5849,  1.8307, -0.5568,  1.1463]],\n",
       "\n",
       "        [[ 0.4434, -0.5125, -1.1083,  0.9996,  0.5958],\n",
       "         [-0.6915, -0.9653,  0.0378,  1.3866, -0.9301],\n",
       "         [ 1.8503, -0.3203, -0.6716, -0.3436, -0.2124],\n",
       "         [ 0.5932,  0.4367, -1.8365,  0.6224, -1.4629]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[0][0]#一个样本的特征张量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4655])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[0][1]#一个样本的标签\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#属性batch_size，查看现在的batch_size是多少\n",
    "dataset.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 1])\n",
      "tensor([[[[-1.1162,  0.4814, -0.4366, -1.0283, -0.7599],\n",
      "          [ 0.9442, -0.5389,  0.8575, -0.0847, -0.0576],\n",
      "          [ 0.6647,  0.3784,  1.4073,  0.1193, -1.9660],\n",
      "          [ 0.1311,  0.9307, -0.4451,  0.3769, -0.1381]],\n",
      "\n",
      "         [[ 0.4021, -0.4931,  0.3754,  1.2682, -0.9277],\n",
      "          [ 0.3087,  1.0354,  1.1180,  0.5830, -0.3299],\n",
      "          [ 1.2121, -1.3158,  0.8034,  1.2662, -0.9069],\n",
      "          [ 1.8108, -0.2319, -0.0207, -0.8490,  1.2687]],\n",
      "\n",
      "         [[ 0.5287, -1.2257, -0.2641,  0.1058,  0.2168],\n",
      "          [ 1.2926, -0.6683,  0.7963,  0.3577, -1.6866],\n",
      "          [-0.0145, -1.7768,  0.4660, -0.0765, -0.2116],\n",
      "          [ 0.0244, -0.3075, -0.3185, -0.6587,  1.0456]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5507,  1.4817, -0.6733, -0.3655, -0.2157],\n",
      "          [ 0.1240,  0.3870,  0.0107, -1.4606,  2.4097],\n",
      "          [ 0.3679, -0.1637, -0.6807, -2.2446, -0.3619],\n",
      "          [-0.7412, -1.1085, -0.7107, -0.4494, -0.7460]],\n",
      "\n",
      "         [[-0.4593, -0.7747, -0.1239,  0.6910,  0.3018],\n",
      "          [-1.5730, -0.8820, -0.2442,  0.5715, -0.7454],\n",
      "          [-0.0612, -0.6762,  0.2904,  1.2597, -0.6273],\n",
      "          [-1.8571,  2.0868, -1.5473,  1.0685, -1.5999]],\n",
      "\n",
      "         [[-0.7721, -0.6462, -0.4386, -0.4191, -0.4070],\n",
      "          [-1.0378, -0.1059, -0.3695,  0.1237,  0.2483],\n",
      "          [ 2.3226,  0.2670,  0.9302,  1.5741, -0.8024],\n",
      "          [-0.0593,  2.4902, -0.9021, -0.8812,  0.1191]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8086,  0.0749,  0.3103, -0.4142,  1.0376],\n",
      "          [-0.4674, -1.8451, -0.1292,  0.3692,  0.4824],\n",
      "          [ 0.4158,  0.1993,  0.8471,  2.0451,  1.1105],\n",
      "          [-1.9454, -1.2030, -0.1316,  0.8115, -1.7249]],\n",
      "\n",
      "         [[-0.2167, -0.6357, -0.0301, -1.5326, -1.6219],\n",
      "          [ 0.4298,  0.5848,  0.8442, -1.1823, -2.2078],\n",
      "          [ 0.1764, -0.9819,  0.2768,  1.7132,  1.2515],\n",
      "          [-0.0780,  2.2816,  0.6782,  0.1175,  0.0817]],\n",
      "\n",
      "         [[ 1.0574,  0.1193,  0.7577, -0.6410, -1.0035],\n",
      "          [ 0.0800,  0.4325,  1.3152, -0.2650, -0.1250],\n",
      "          [-0.5409, -0.2403,  0.6296,  0.3343,  1.1543],\n",
      "          [-0.1979,  0.7517, -2.1128,  1.3394,  0.2986]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.7170, -0.1535, -0.7131,  2.0886,  0.1127],\n",
      "          [ 2.6235, -0.1739, -0.0063, -2.4911, -1.3627],\n",
      "          [ 1.3429,  0.1391,  0.5157,  0.8846,  1.1163],\n",
      "          [-2.2839, -1.0178, -0.0236,  0.2447,  1.5330]],\n",
      "\n",
      "         [[ 0.2862, -2.2323,  0.8778,  0.0675, -1.1395],\n",
      "          [-1.4662, -0.8160,  0.4977, -0.8625,  1.6905],\n",
      "          [ 0.0940,  2.2597,  0.4287,  0.8001,  0.4834],\n",
      "          [-0.8096,  0.2669,  1.3225, -0.1944, -0.0413]],\n",
      "\n",
      "         [[-0.5018, -0.0284,  1.7525, -1.5718,  0.9497],\n",
      "          [ 0.6855,  0.7043,  0.6189, -0.1740,  1.1691],\n",
      "          [-1.8914,  0.0353, -0.2358, -0.1117, -1.2684],\n",
      "          [-0.0059, -0.2401,  1.4114, -1.8091,  0.1020]]],\n",
      "\n",
      "\n",
      "        [[[-0.9788,  1.8490, -0.2601, -0.0901,  0.8489],\n",
      "          [-0.2145,  3.1676,  0.6957, -0.8360, -0.2599],\n",
      "          [-0.4939, -2.0109,  2.1658,  1.2019, -0.3803],\n",
      "          [ 0.9460,  0.8264,  0.6572,  1.2563,  1.5545]],\n",
      "\n",
      "         [[ 0.5899, -0.2480, -0.3532, -0.5732, -0.4758],\n",
      "          [-1.0504, -0.9840, -1.2373,  1.3247,  1.4332],\n",
      "          [ 0.1627,  0.6498, -0.6792,  0.3404,  1.1604],\n",
      "          [ 2.1071,  0.5558, -0.9032, -0.4856, -0.6087]],\n",
      "\n",
      "         [[ 0.6801,  1.1353, -0.6641,  0.4274,  0.2780],\n",
      "          [-0.7153, -2.5439,  0.0898, -0.4811,  0.9605],\n",
      "          [ 0.7295, -0.7044,  0.1110, -0.0558,  0.6070],\n",
      "          [-0.1531,  2.1004, -0.9139, -0.0720,  0.1082]]],\n",
      "\n",
      "\n",
      "        [[[-0.4287,  0.0433,  0.1922,  1.0739, -0.3315],\n",
      "          [ 0.1107,  1.4379, -0.5106, -0.8838,  1.3730],\n",
      "          [-1.2613,  0.2586, -1.0183,  0.1105,  0.2343],\n",
      "          [-0.4944,  0.6786,  0.4304, -0.7800, -0.9863]],\n",
      "\n",
      "         [[ 1.7271, -0.3121,  1.9555,  1.2474,  1.4676],\n",
      "          [-0.9358,  0.2819, -0.2683, -0.3492, -0.6058],\n",
      "          [ 0.2713,  0.3549, -0.0195,  0.4793, -0.6090],\n",
      "          [ 0.3718, -0.1342,  0.3533, -1.1505,  1.2804]],\n",
      "\n",
      "         [[ 1.2333,  0.4016, -0.2591, -0.6184, -1.0506],\n",
      "          [-2.9057,  2.1259,  0.0668,  0.2779,  1.3888],\n",
      "          [ 2.5769, -0.0547,  0.6863, -1.2633, -0.5896],\n",
      "          [-2.7845,  0.8873, -0.1775, -0.9395,  0.2119]]]]) tensor([[ 9.2144e-01],\n",
      "        [-5.3029e-01],\n",
      "        [-1.1813e+00],\n",
      "        [-2.0784e+00],\n",
      "        [-8.4923e-01],\n",
      "        [ 1.3955e-01],\n",
      "        [-1.1382e+00],\n",
      "        [-8.2350e-02],\n",
      "        [ 3.8635e-01],\n",
      "        [-1.2010e-01],\n",
      "        [ 5.9404e-04],\n",
      "        [ 1.1624e+00],\n",
      "        [ 1.0703e+00],\n",
      "        [-7.4131e-01],\n",
      "        [ 9.4712e-01],\n",
      "        [ 1.4475e+00],\n",
      "        [-1.9592e-01],\n",
      "        [-1.0877e+00],\n",
      "        [ 7.0407e-02],\n",
      "        [-2.2961e+00],\n",
      "        [-3.5258e-01],\n",
      "        [ 9.0349e-01],\n",
      "        [ 2.1515e+00],\n",
      "        [ 2.5904e+00],\n",
      "        [-9.3401e-01],\n",
      "        [-1.9426e+00],\n",
      "        [-6.7557e-02],\n",
      "        [-1.2762e-01],\n",
      "        [ 4.6552e-01],\n",
      "        [-4.1905e-01],\n",
      "        [ 9.1176e-01],\n",
      "        [-2.3784e-01],\n",
      "        [ 2.9583e-01],\n",
      "        [-2.0312e+00],\n",
      "        [ 1.0637e+00],\n",
      "        [-4.3501e-01],\n",
      "        [-7.2376e-01],\n",
      "        [-1.5168e+00],\n",
      "        [-1.3001e+00],\n",
      "        [ 7.5094e-02],\n",
      "        [ 6.1242e-02],\n",
      "        [-1.4148e+00],\n",
      "        [-1.5448e-01],\n",
      "        [ 1.3429e+00],\n",
      "        [ 5.5329e-01],\n",
      "        [-4.0170e-01],\n",
      "        [ 6.5791e-01],\n",
      "        [-1.4260e+00],\n",
      "        [-6.8855e-01],\n",
      "        [ 5.2062e-01],\n",
      "        [ 1.0426e+00],\n",
      "        [ 1.4824e+00],\n",
      "        [ 1.9854e+00],\n",
      "        [-4.6292e-02],\n",
      "        [-1.0000e+00],\n",
      "        [ 4.4217e-01],\n",
      "        [ 1.3020e+00],\n",
      "        [-9.2220e-02],\n",
      "        [ 9.7511e-01],\n",
      "        [-7.3830e-02],\n",
      "        [-4.6259e-01],\n",
      "        [-9.7859e-01],\n",
      "        [ 1.0795e+00],\n",
      "        [ 4.5316e-01],\n",
      "        [ 1.1234e+00],\n",
      "        [-9.9923e-01],\n",
      "        [-1.4357e-01],\n",
      "        [-3.1434e-01],\n",
      "        [-9.6130e-01],\n",
      "        [-2.8776e+00],\n",
      "        [-1.3177e+00],\n",
      "        [-1.3808e-01],\n",
      "        [-6.6068e-01],\n",
      "        [ 4.1064e-01],\n",
      "        [ 2.3734e-01],\n",
      "        [ 3.0057e-01],\n",
      "        [ 8.6518e-01],\n",
      "        [ 5.1925e-01],\n",
      "        [ 1.2064e+00],\n",
      "        [-7.1899e-01],\n",
      "        [-7.6734e-01],\n",
      "        [-1.2438e+00],\n",
      "        [-1.7516e+00],\n",
      "        [-1.5493e-01],\n",
      "        [-2.4449e-02],\n",
      "        [-7.0321e-01],\n",
      "        [-2.6138e+00],\n",
      "        [-5.7830e-01],\n",
      "        [ 2.0246e+00],\n",
      "        [-1.0438e+00],\n",
      "        [-1.2948e+00],\n",
      "        [ 6.6273e-01],\n",
      "        [-7.3544e-01],\n",
      "        [ 3.3886e-01],\n",
      "        [ 2.0341e-01],\n",
      "        [ 6.1952e-01],\n",
      "        [ 7.9389e-01],\n",
      "        [ 2.0049e-01],\n",
      "        [ 8.7098e-01],\n",
      "        [ 5.5957e-01],\n",
      "        [ 3.4107e-01],\n",
      "        [-2.3596e-01],\n",
      "        [-2.5173e+00],\n",
      "        [-9.3343e-02],\n",
      "        [ 1.0191e+00],\n",
      "        [-7.2500e-01],\n",
      "        [-4.3257e-01],\n",
      "        [ 1.1875e-01],\n",
      "        [-3.2556e-02],\n",
      "        [ 6.9387e-01],\n",
      "        [-1.3495e+00],\n",
      "        [ 8.6968e-01],\n",
      "        [-6.7975e-01],\n",
      "        [-1.7635e+00],\n",
      "        [ 1.9726e+00],\n",
      "        [ 1.1093e-01],\n",
      "        [ 2.5223e-01],\n",
      "        [-9.6979e-01],\n",
      "        [-3.1311e-01],\n",
      "        [-9.3556e-01]])\n",
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 1])\n",
      "tensor([[[[-1.3853,  0.5434, -1.5681,  0.9239,  0.9159],\n",
      "          [ 0.8820, -1.1052, -0.5500, -1.1366, -0.4853],\n",
      "          [-1.5424, -0.3074,  0.5500,  2.0553,  0.6465],\n",
      "          [ 1.2068, -0.7147,  1.2319, -2.1718, -1.0080]],\n",
      "\n",
      "         [[-1.0562, -0.0105, -1.8589,  0.1688,  1.4930],\n",
      "          [-0.8404, -0.8122,  0.7119, -0.8142, -0.7003],\n",
      "          [ 1.2574, -0.1177, -0.1745, -0.6603,  0.9621],\n",
      "          [ 0.6433, -0.4769, -0.7247,  1.3859, -0.7365]],\n",
      "\n",
      "         [[-0.5703,  0.4900, -1.5614,  1.1368, -0.0576],\n",
      "          [-0.6246,  0.0308, -1.4591, -0.7585,  0.2983],\n",
      "          [ 0.0212,  0.3977,  0.3458, -0.4850, -2.0200],\n",
      "          [-1.2889,  1.6282, -0.0464, -0.6660, -0.4064]]],\n",
      "\n",
      "\n",
      "        [[[-2.5114, -1.6950,  1.6754, -0.6266,  1.2057],\n",
      "          [ 1.3628,  1.7636,  0.9366, -1.0726,  0.2577],\n",
      "          [ 0.1381,  0.8668, -0.2338,  1.8422, -0.6857],\n",
      "          [ 1.0183,  0.1590, -0.2437,  2.6790,  0.6769]],\n",
      "\n",
      "         [[-0.7064,  0.1763, -1.0379,  0.2589,  1.4566],\n",
      "          [-1.1202,  0.1392, -1.2339, -1.2369, -0.0999],\n",
      "          [-1.1365, -0.9175, -1.7448,  0.9369,  0.1837],\n",
      "          [ 0.3384,  0.5538,  0.6273, -0.7145,  0.1774]],\n",
      "\n",
      "         [[ 1.0553, -2.4212, -0.6880,  0.5703, -1.5777],\n",
      "          [ 0.1707,  0.2337, -0.4299, -0.7090,  0.4379],\n",
      "          [ 0.2304,  0.1543, -0.2580,  0.1926, -0.5070],\n",
      "          [-0.8826, -0.0417,  0.0494, -1.2772, -0.3327]]],\n",
      "\n",
      "\n",
      "        [[[-0.2106, -1.4635, -1.6260, -0.5284, -0.2883],\n",
      "          [-1.6023,  1.2193,  1.7932,  1.6326,  1.9727],\n",
      "          [-1.2769,  0.5810, -2.5815, -0.1856, -0.3642],\n",
      "          [ 0.5595,  0.9143, -0.8136,  0.5904,  0.3903]],\n",
      "\n",
      "         [[ 2.2362, -0.0405,  0.0777,  0.3198,  1.5691],\n",
      "          [-0.3987, -0.1287, -1.1763,  0.9454,  0.5708],\n",
      "          [ 1.2112, -0.0623,  0.4139,  0.1888, -0.9940],\n",
      "          [ 1.4389, -0.1344,  1.1541, -1.0023,  0.8461]],\n",
      "\n",
      "         [[-0.2991,  0.2467, -0.1675,  0.9120, -1.6031],\n",
      "          [-0.5189,  0.4388, -0.5408,  1.8561, -0.1045],\n",
      "          [ 0.4737, -0.5691, -0.2828, -1.2554, -0.1893],\n",
      "          [ 0.6632, -0.0372, -1.3319, -0.5284,  1.2612]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2113, -0.7254, -0.2044, -0.0074,  0.4713],\n",
      "          [ 0.5510,  0.9650, -1.4882,  0.2399, -0.6741],\n",
      "          [ 0.5795, -1.1204,  0.1978, -0.2667, -0.3579],\n",
      "          [-1.4283,  0.5216,  0.5907,  0.3189, -0.2846]],\n",
      "\n",
      "         [[ 0.3500,  0.3415, -0.6652,  0.4490,  0.5929],\n",
      "          [ 1.0654, -1.3631,  0.4991,  1.1200,  1.9533],\n",
      "          [-1.3917, -0.1017,  1.8615,  0.9069, -0.0250],\n",
      "          [ 0.5284,  0.8726, -0.3150, -0.5627,  0.2878]],\n",
      "\n",
      "         [[-2.1227,  0.2882,  0.7531, -0.1028, -2.7471],\n",
      "          [ 0.0812, -0.6516,  1.7209,  0.2671, -0.4449],\n",
      "          [-0.1356,  0.1160, -1.2748, -0.0807,  1.8721],\n",
      "          [-0.9644,  0.7187, -1.6379,  2.2415, -1.9764]]],\n",
      "\n",
      "\n",
      "        [[[-0.1622, -0.6945,  0.2664,  0.5715,  1.8927],\n",
      "          [-0.1404,  0.6555,  1.2175, -0.1429, -0.1814],\n",
      "          [-0.2379,  1.5822, -1.0870, -1.2441,  1.3491],\n",
      "          [ 0.5541,  0.6720,  0.3489, -1.7720, -0.0437]],\n",
      "\n",
      "         [[ 0.4907,  0.2185,  0.6065,  0.2748,  0.4870],\n",
      "          [-0.8989,  0.6214,  0.3587,  0.5546, -0.5273],\n",
      "          [-0.2457, -0.2518, -1.2055,  0.8203,  1.4264],\n",
      "          [-0.0471, -0.1350, -0.2786,  0.7148, -1.4924]],\n",
      "\n",
      "         [[ 0.8292,  0.2290,  0.4960, -0.2604, -0.5803],\n",
      "          [-0.9118,  0.4223, -0.7095,  0.9968,  0.8663],\n",
      "          [ 0.3376,  0.1087, -0.5802, -1.0835,  1.1729],\n",
      "          [-0.3443,  0.4514,  0.1488,  0.7447,  0.1972]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9468, -2.0888, -0.7590,  2.6135,  0.7105],\n",
      "          [-0.6582, -1.2567,  1.0965,  0.2152,  1.6919],\n",
      "          [-1.1297,  0.7089,  0.3913, -0.1015,  0.6572],\n",
      "          [-2.5761, -0.8122, -1.3787, -0.4511,  0.6600]],\n",
      "\n",
      "         [[ 0.6495,  0.9788, -0.0049, -2.5882,  2.0634],\n",
      "          [-0.1275,  0.6423,  0.6775, -0.4631, -0.3297],\n",
      "          [-2.0769, -1.0578,  0.6251,  1.5827, -0.0880],\n",
      "          [ 1.8299,  0.9988,  0.2741, -0.3003,  0.3814]],\n",
      "\n",
      "         [[-0.4514, -0.4588, -1.5180,  1.2121,  2.0527],\n",
      "          [-0.5250,  0.6098,  1.0021,  0.1254, -1.5497],\n",
      "          [ 1.1925, -0.7263, -1.0560, -0.2023,  1.3864],\n",
      "          [ 0.4241, -2.1954,  0.6349, -0.1401, -0.6832]]]]) tensor([[-0.3450],\n",
      "        [-0.2764],\n",
      "        [-0.4615],\n",
      "        [-0.3706],\n",
      "        [-0.1553],\n",
      "        [ 1.3860],\n",
      "        [ 0.5049],\n",
      "        [ 1.5194],\n",
      "        [-0.0641],\n",
      "        [-0.5965],\n",
      "        [-1.2995],\n",
      "        [-0.0545],\n",
      "        [ 0.0711],\n",
      "        [-0.6831],\n",
      "        [-0.7084],\n",
      "        [ 0.4489],\n",
      "        [ 0.1446],\n",
      "        [ 1.1696],\n",
      "        [ 0.9347],\n",
      "        [ 0.1091],\n",
      "        [ 0.5890],\n",
      "        [ 1.1788],\n",
      "        [-0.1994],\n",
      "        [ 0.7320],\n",
      "        [-2.3446],\n",
      "        [ 0.3633],\n",
      "        [ 1.5232],\n",
      "        [-0.2701],\n",
      "        [-1.5557],\n",
      "        [-0.4325],\n",
      "        [ 1.9006],\n",
      "        [ 1.2296],\n",
      "        [ 0.3601],\n",
      "        [-1.1122],\n",
      "        [-1.2465],\n",
      "        [-0.7968],\n",
      "        [-0.9931],\n",
      "        [-0.1478],\n",
      "        [-1.3531],\n",
      "        [ 0.9376],\n",
      "        [ 0.8874],\n",
      "        [ 0.6839],\n",
      "        [-0.6952],\n",
      "        [ 1.9014],\n",
      "        [ 0.0336],\n",
      "        [ 1.5456],\n",
      "        [-1.7188],\n",
      "        [ 1.0630],\n",
      "        [-0.5047],\n",
      "        [ 1.5615],\n",
      "        [-0.7669],\n",
      "        [ 1.2044],\n",
      "        [-0.0678],\n",
      "        [ 1.1230],\n",
      "        [ 0.0194],\n",
      "        [-0.2727],\n",
      "        [-0.8741],\n",
      "        [ 0.1929],\n",
      "        [-0.3813],\n",
      "        [-1.4238],\n",
      "        [ 0.5063],\n",
      "        [-1.3898],\n",
      "        [ 2.1017],\n",
      "        [-0.3791],\n",
      "        [ 0.3806],\n",
      "        [-0.6602],\n",
      "        [-2.0267],\n",
      "        [ 0.0659],\n",
      "        [ 0.8098],\n",
      "        [-0.4903],\n",
      "        [ 0.3320],\n",
      "        [ 1.6519],\n",
      "        [-1.5238],\n",
      "        [-0.2065],\n",
      "        [ 0.1753],\n",
      "        [ 0.2559],\n",
      "        [-1.2161],\n",
      "        [-0.2232],\n",
      "        [-0.4931],\n",
      "        [ 3.0149],\n",
      "        [-2.7349],\n",
      "        [ 1.0938],\n",
      "        [-0.6087],\n",
      "        [ 0.1558],\n",
      "        [-0.1160],\n",
      "        [-0.1993],\n",
      "        [ 1.0413],\n",
      "        [ 0.4547],\n",
      "        [-1.3387],\n",
      "        [-1.5062],\n",
      "        [ 0.9413],\n",
      "        [-1.1506],\n",
      "        [-0.1190],\n",
      "        [-0.6399],\n",
      "        [-0.1882],\n",
      "        [ 0.8643],\n",
      "        [-0.5041],\n",
      "        [ 0.6267],\n",
      "        [-0.9712],\n",
      "        [-1.5097],\n",
      "        [ 0.5141],\n",
      "        [-0.5428],\n",
      "        [ 1.2353],\n",
      "        [-1.6522],\n",
      "        [-0.0311],\n",
      "        [ 0.1781],\n",
      "        [-0.9286],\n",
      "        [ 0.6314],\n",
      "        [ 0.9421],\n",
      "        [ 0.2906],\n",
      "        [-0.7804],\n",
      "        [-1.3197],\n",
      "        [ 1.2807],\n",
      "        [-0.3585],\n",
      "        [ 2.4760],\n",
      "        [-1.3176],\n",
      "        [ 0.4250],\n",
      "        [ 0.2344],\n",
      "        [ 0.7776],\n",
      "        [ 0.7644]])\n",
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 1])\n",
      "tensor([[[[ 9.6198e-01,  3.3201e-01, -9.7216e-02, -9.2629e-01,  1.9247e+00],\n",
      "          [ 2.7358e-01,  1.2407e-01, -1.0779e+00, -2.7679e-01, -8.6764e-01],\n",
      "          [ 6.9456e-01,  4.3013e-01, -1.9296e+00,  1.2879e-01,  1.7771e+00],\n",
      "          [ 2.4676e-01,  6.5466e-01, -4.6067e-01, -3.4330e-01,  3.9114e-02]],\n",
      "\n",
      "         [[-1.3801e+00, -1.5072e-01,  4.5193e-01, -1.3395e+00, -6.3845e-01],\n",
      "          [ 1.4188e+00,  6.6511e-01,  2.5842e-01,  8.6079e-01,  4.7119e-01],\n",
      "          [-5.7861e-02,  2.1434e+00,  3.9518e-01, -1.2900e+00, -8.8238e-01],\n",
      "          [ 5.2097e-01, -7.6870e-01, -2.5059e-01,  1.1209e-01,  2.4177e+00]],\n",
      "\n",
      "         [[-3.1621e-02,  8.1287e-01, -6.2320e-01,  3.7088e-01, -1.2801e+00],\n",
      "          [ 5.8020e-01, -1.8478e+00,  8.7500e-01,  1.8686e+00, -3.0884e-01],\n",
      "          [ 2.1791e-01, -1.7960e+00,  1.6578e-02,  1.4235e+00, -3.9965e-01],\n",
      "          [ 1.1031e-01, -3.7633e-01,  1.7669e+00, -2.9434e-01,  3.6140e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0133e-01, -4.1490e-01, -1.8714e+00,  6.8957e-01, -1.2455e-02],\n",
      "          [-3.4650e-02, -3.8744e-01, -6.5844e-01, -8.0290e-03, -6.5359e-01],\n",
      "          [-2.9021e-01, -6.8768e-01,  8.4781e-02,  1.7286e-01,  2.1378e-01],\n",
      "          [ 8.3758e-01, -9.2418e-01,  1.0812e+00,  7.5768e-03,  2.6410e-01]],\n",
      "\n",
      "         [[ 7.9114e-01, -5.9950e-02, -2.5816e-01, -1.0875e-01,  2.9062e-01],\n",
      "          [-1.5280e+00, -1.4900e-02,  1.9553e-01,  2.0137e+00,  7.2299e-01],\n",
      "          [-1.2962e+00, -1.6324e-01,  2.0078e+00,  1.2134e-01,  2.3344e-01],\n",
      "          [ 2.1824e+00,  1.1112e+00, -7.2147e-01,  7.0747e-02, -3.4997e-01]],\n",
      "\n",
      "         [[ 7.4999e-01, -1.3174e+00, -3.4157e-01, -2.1034e-01,  3.0924e-01],\n",
      "          [-9.6091e-01, -1.1123e+00,  9.0770e-01,  1.3450e+00, -1.8394e+00],\n",
      "          [-7.6744e-01,  3.7856e-01, -5.6414e-01,  1.3522e-01,  1.0186e-01],\n",
      "          [-2.4830e-01,  2.7301e-01, -3.7657e-01, -2.2807e+00, -1.6899e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7518e+00,  7.2333e-01,  1.8481e-01, -1.0559e+00,  1.0745e+00],\n",
      "          [ 8.6679e-01, -1.2218e+00, -1.9391e+00,  1.2623e+00, -1.2029e-01],\n",
      "          [ 1.6591e+00,  2.7118e-01,  3.1085e-01,  1.0706e-01, -5.1702e-01],\n",
      "          [-9.6234e-02,  9.5529e-02,  1.9336e-01, -6.8395e-01,  9.3272e-01]],\n",
      "\n",
      "         [[ 9.3862e-01,  1.0668e+00,  4.3421e-01,  7.5443e-01, -3.1656e+00],\n",
      "          [-2.0861e-01,  5.8816e-01,  3.2658e-01,  1.9207e+00,  7.8680e-01],\n",
      "          [ 1.1917e+00,  1.5341e+00,  6.8292e-01, -1.1872e+00, -1.8899e+00],\n",
      "          [-1.7394e-01,  6.0369e-01,  6.1152e-01,  1.4921e+00,  1.7697e+00]],\n",
      "\n",
      "         [[-4.8797e-01, -5.6051e-01, -9.9167e-01, -4.8827e-01, -1.1589e+00],\n",
      "          [-1.3981e+00, -3.3453e-01, -2.0997e+00,  3.9910e-01,  3.1196e-01],\n",
      "          [ 1.3164e+00, -2.4464e+00, -1.1351e+00, -1.5813e+00, -1.1045e+00],\n",
      "          [ 1.9421e-01, -1.4172e+00, -2.4866e-01, -1.1185e-01, -2.5332e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.4465e-01, -3.9055e-01, -9.3675e-01,  1.3237e+00,  3.2740e-02],\n",
      "          [ 1.4735e+00,  1.2476e-01, -4.9081e-01, -5.7872e-01,  1.1944e+00],\n",
      "          [-8.5025e-01, -4.2290e-01, -1.3739e-01, -7.4971e-01, -8.0121e-01],\n",
      "          [-5.2026e-01, -2.7471e-01, -1.1953e+00,  9.0322e-04, -1.3160e+00]],\n",
      "\n",
      "         [[-1.3289e-01,  8.9791e-01,  6.0766e-04, -2.0534e-01, -1.0083e+00],\n",
      "          [ 4.5231e-01,  1.6016e+00,  2.8696e-01, -1.0933e+00, -6.2990e-01],\n",
      "          [ 2.1956e+00,  3.2542e-03, -2.5725e-01,  4.5081e-01, -3.2975e-01],\n",
      "          [-1.1540e+00, -1.2063e+00, -3.5793e-01,  8.6698e-01,  1.3235e-01]],\n",
      "\n",
      "         [[ 2.2332e-01, -6.7329e-01, -2.2691e-01,  4.2286e-01, -1.3276e-01],\n",
      "          [-1.7087e+00,  7.0329e-01,  2.0412e+00,  4.5522e-01, -5.6802e-01],\n",
      "          [-2.8365e-01,  1.6246e-01,  8.1364e-01,  3.4220e-01, -5.5273e-01],\n",
      "          [ 5.5289e-01, -6.8304e-02, -1.8167e+00, -3.5789e-01,  2.8337e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.4373e-02, -1.3448e-01, -1.0005e+00, -6.9088e-01,  4.3682e-01],\n",
      "          [-3.8345e-02, -6.9156e-01,  1.3150e+00,  7.2477e-01,  1.6719e+00],\n",
      "          [ 3.3996e-01,  2.6370e-01,  7.5240e-01,  8.1893e-01, -3.0215e-02],\n",
      "          [-9.6935e-01,  3.0418e-01,  1.1472e+00,  1.3794e+00,  1.4929e+00]],\n",
      "\n",
      "         [[ 1.1174e+00,  9.9211e-01, -8.5436e-01,  2.0264e+00,  1.0520e-01],\n",
      "          [ 3.2041e-01, -1.0466e+00,  2.0041e+00,  2.7714e-01,  5.7757e-01],\n",
      "          [ 7.0133e-01,  7.5760e-01,  2.1450e-01,  2.5638e-01, -2.4295e+00],\n",
      "          [-2.4230e-01,  1.2929e-01,  2.7487e-01, -3.5302e-01, -8.6177e-01]],\n",
      "\n",
      "         [[ 5.5669e-02, -5.5189e-02,  2.6458e-01,  2.4141e-01, -7.0643e-01],\n",
      "          [-5.4266e-01, -2.2046e+00, -1.2079e+00, -9.1845e-01, -6.8765e-02],\n",
      "          [-1.1962e+00,  1.5735e-01,  5.0938e-01,  3.7873e-01,  1.3325e-01],\n",
      "          [ 1.1552e+00, -1.0256e+00, -6.0398e-01,  8.1824e-01, -1.1663e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1452e+00,  5.3813e-01,  6.2532e-02, -4.8482e-02,  2.8752e-01],\n",
      "          [ 5.2181e-01,  1.0958e+00,  3.7315e-01, -2.1170e-01,  1.6932e+00],\n",
      "          [-1.7082e+00,  2.0691e-01,  6.8064e-01,  3.2122e-02, -4.5124e-02],\n",
      "          [-1.6319e+00,  5.6828e-02,  5.3409e-01,  8.2499e-01,  1.9972e+00]],\n",
      "\n",
      "         [[-4.0126e-01, -1.2456e+00, -6.3294e-01,  1.1063e-01, -2.5795e+00],\n",
      "          [-8.8765e-01,  1.3334e-01, -6.0190e-02, -1.5130e-01, -3.3489e-01],\n",
      "          [-4.8931e-01,  2.1873e-01, -8.1803e-01, -4.7823e-01,  1.0453e+00],\n",
      "          [-7.0627e-01, -1.0209e-01,  2.2495e-01, -2.4996e-01,  1.1062e+00]],\n",
      "\n",
      "         [[ 2.3739e+00,  7.0405e-01,  1.6732e-02, -9.4876e-01,  9.6270e-01],\n",
      "          [-6.6696e-02,  8.5036e-01, -4.0324e-01,  1.0125e+00,  1.0514e+00],\n",
      "          [-2.9810e-02,  1.3982e+00, -9.0823e-01, -1.4705e+00, -2.7251e-01],\n",
      "          [ 1.2317e+00,  3.0554e-01, -5.2233e-01, -7.8148e-02,  8.3796e-01]]]]) tensor([[-1.1268e+00],\n",
      "        [-1.1556e-01],\n",
      "        [-2.2980e-01],\n",
      "        [ 1.0338e-01],\n",
      "        [-2.4072e-01],\n",
      "        [-1.1728e+00],\n",
      "        [-4.8714e-01],\n",
      "        [ 2.0006e-01],\n",
      "        [-2.6258e-02],\n",
      "        [ 4.0705e-01],\n",
      "        [ 9.6267e-01],\n",
      "        [ 3.2434e-01],\n",
      "        [ 4.4198e-01],\n",
      "        [ 4.8638e-01],\n",
      "        [-6.2501e-01],\n",
      "        [-6.1898e-01],\n",
      "        [-8.1262e-01],\n",
      "        [ 1.4577e+00],\n",
      "        [-9.5946e-01],\n",
      "        [ 8.0926e-01],\n",
      "        [ 1.6574e+00],\n",
      "        [-5.0619e-01],\n",
      "        [-1.5764e+00],\n",
      "        [ 2.1148e+00],\n",
      "        [-3.5920e-01],\n",
      "        [ 3.4127e-01],\n",
      "        [ 4.0004e-01],\n",
      "        [ 1.2540e+00],\n",
      "        [ 1.9973e-01],\n",
      "        [ 4.8791e-01],\n",
      "        [-8.6986e-01],\n",
      "        [-6.8848e-01],\n",
      "        [ 3.6265e-01],\n",
      "        [-1.1367e-02],\n",
      "        [ 2.0471e+00],\n",
      "        [ 1.2380e+00],\n",
      "        [ 5.6702e-01],\n",
      "        [-2.7113e-01],\n",
      "        [-2.9688e+00],\n",
      "        [-2.0654e+00],\n",
      "        [ 1.0609e-01],\n",
      "        [ 1.3053e+00],\n",
      "        [ 1.6865e-01],\n",
      "        [-1.2821e-01],\n",
      "        [-8.6297e-01],\n",
      "        [ 2.7265e-01],\n",
      "        [ 3.5012e-01],\n",
      "        [ 1.3731e+00],\n",
      "        [-1.3232e+00],\n",
      "        [ 4.0467e-01],\n",
      "        [ 6.9306e-01],\n",
      "        [-3.8116e-01],\n",
      "        [ 8.3314e-01],\n",
      "        [-4.1260e-01],\n",
      "        [-5.9517e-01],\n",
      "        [ 1.4798e-01],\n",
      "        [-1.8856e+00],\n",
      "        [-9.2591e-01],\n",
      "        [ 7.5370e-01],\n",
      "        [ 2.0476e-01],\n",
      "        [ 1.0194e-01],\n",
      "        [-1.2442e+00],\n",
      "        [ 6.0666e-01],\n",
      "        [ 3.9842e-01],\n",
      "        [ 1.0896e+00],\n",
      "        [ 1.6511e+00],\n",
      "        [-5.2536e-01],\n",
      "        [ 1.5414e+00],\n",
      "        [ 1.8326e-01],\n",
      "        [ 1.5731e+00],\n",
      "        [-3.4932e-02],\n",
      "        [ 7.6784e-01],\n",
      "        [ 1.1991e+00],\n",
      "        [-3.0976e-01],\n",
      "        [-6.8355e-01],\n",
      "        [-1.4731e+00],\n",
      "        [-3.0571e-01],\n",
      "        [-8.9695e-02],\n",
      "        [-6.4476e-01],\n",
      "        [-7.7074e-02],\n",
      "        [-1.4065e+00],\n",
      "        [ 1.0475e+00],\n",
      "        [ 8.0824e-01],\n",
      "        [ 2.1177e+00],\n",
      "        [-4.6625e-01],\n",
      "        [-1.6740e-02],\n",
      "        [-3.0348e-01],\n",
      "        [ 7.3558e-01],\n",
      "        [ 1.2256e+00],\n",
      "        [-4.3055e-01],\n",
      "        [ 8.4635e-01],\n",
      "        [-1.0623e+00],\n",
      "        [-5.8191e-01],\n",
      "        [ 1.0484e-01],\n",
      "        [ 1.8973e-01],\n",
      "        [-1.3833e+00],\n",
      "        [ 1.8095e-01],\n",
      "        [-5.4094e-01],\n",
      "        [ 6.3320e-01],\n",
      "        [ 8.3573e-01],\n",
      "        [-6.3673e-01],\n",
      "        [-1.7449e+00],\n",
      "        [ 2.8602e-01],\n",
      "        [-9.5070e-01],\n",
      "        [-1.1843e-01],\n",
      "        [-1.1454e+00],\n",
      "        [ 1.0940e+00],\n",
      "        [ 6.4103e-02],\n",
      "        [ 5.7318e-01],\n",
      "        [ 1.3915e+00],\n",
      "        [-2.0457e-01],\n",
      "        [-5.2623e-01],\n",
      "        [ 9.4754e-01],\n",
      "        [-7.8714e-01],\n",
      "        [-4.1550e-01],\n",
      "        [ 1.3619e+00],\n",
      "        [-8.8562e-04],\n",
      "        [ 1.8426e-01],\n",
      "        [ 3.1941e-02],\n",
      "        [-3.6050e-01]])\n"
     ]
    }
   ],
   "source": [
    "#我们在迭代的时候，常常这样使用：\n",
    "for batch_idx, (x,y) in enumerate(dataset):\n",
    "    #sigma = net(x)\n",
    "    #loss = lossfn(sigma, y)\n",
    "    #loss.backward()\n",
    "    #opt.step()\n",
    "    #opt.zero_grad()\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(x,y)\n",
    "    if batch_idx == 2:\n",
    "        break \n",
    "#为了演示用，所以打断，在正常的循环里是不会打断的\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、在MINST-FASHION上实现神经网络的学习流程\n",
    "\n",
    "**神经网络建模流程**  \n",
    "1. 设置步长lr ，动量值gamma，迭代次数epoches，batch_size等信息，（如果需要）设置初始权重$w_0$\n",
    " 2. 导入数据，将数据切分成batches\n",
    " 3. 定义神经网络架构\n",
    " 4. 定义损失函数 ，如果需要的话，将损失函数调整成凸函数，以便求解最小值\n",
    " 5. 定义所使用的优化算法\n",
    " 6. 开始在epoches和batch上循环，执行优化算法：  \n",
    "    6.1  调整数据结构，确定数据能够在神经网络、损失函数和优化算法中顺利运行   \n",
    "    6.2  完成向前传播，计算初始损失    \n",
    "    6.3  利用反向传播，在损失函数$L(w)$上对每一个$w$求偏导数\n",
    "    6.4  迭代当前权重  \n",
    "    6.5  清空本轮梯度  \n",
    "    6.6  完成模型进度与效果监控(loss accuracy)  \n",
    " 7. 输出结果\n",
    "\n",
    "\n",
    "- `torch.max(l,dim=)`\n",
    "  - 不写dim 返回全部元素的最大值\n",
    "  - dim=0 返回每一列的最大值以及索引\n",
    "  - dim=1 返回每一行的最大值以及索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.导库，设置初始值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#确定数据、确定优先需要设置的值\n",
    "lr = 0.15\n",
    "gamma = 0.8\n",
    "epochs = 5\n",
    "bs = 128  # 使用图像数据时，使用32的倍数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.导入数据，分割小批量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms # 处理数据模块\n",
    "\n",
    "# dataloader、TensorDataset - 对数据的结构、归纳方式进行变化\n",
    "# torchvision.transforms - 对数据集的数字本身进行修改\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初次运行时会下载，需要等待较长时间\n",
    "mnist = torchvision.datasets.FashionMNIST(\n",
    "    root='C:\\Pythonwork\\DEEP LEARNING\\WEEK 3\\Datasets\\FashionMNIST'  # 下载的目录\n",
    "   , train=True\n",
    "   , download=True\n",
    "   , transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape  # 特征张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.targets.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看标签的类别\n",
    "mnist.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt中不支持tensor\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[0][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f7dc7bbb88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看图形的模样\n",
    "plt.imshow(mnist[0][0].view(28,28).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f7dc86eb48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist[3000][0].view(28,28).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "#————————————————————————————进行小批量划分————————————————————————————\n",
    "batchdata = DataLoader(mnist,batch_size=bs,shuffle=True)\n",
    "\n",
    "for x,y in batchdata:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data[0].numel()  # 张量中有多少个元素 28*28\n",
    "\n",
    "# 对于图像数据总是把后面的维度拉平，相乘起来变成特征输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "input_ = mnist.data[0].numel() \n",
    "output_ = len(mnist.targets.unique())  # 10分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.定义神经网络的架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#————————————————————————————定义神经网络的架构————————————————————————————\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=10,out_features=2):\n",
    "        super().__init__()\n",
    "        self.normalize = nn.BatchNorm2d(num_features=1)\n",
    "        self.linear1 = nn.Linear(in_features,128,bias=False)\n",
    "        self.output = nn.Linear(128,out_features,bias=False)  # 2层神经网络\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.normalize(x)\n",
    "        x = x.view(-1,28*28)\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        sigma2 = F.log_softmax(self.output(sigma1),dim=1)\n",
    "        return sigma2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view(-1,)  # 需要对数据结构进行改变\n",
    "# -1表示占位符，表示自动计算-1这个位置上的维度应该是多少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#————————————————————————————定义损失函数、优化算法————————————————————————————\n",
    "# 定义一个训练函数\n",
    "\n",
    "def fit(net,batchdata,lr=0.01,epochs=5,gamma=0):\n",
    "\n",
    "    criterion = nn.NLLLoss()  # 定义损失函数\n",
    "    opt = optim.SGD(net.parameters(),lr=lr,momentum=gamma)  # 小批量梯度下降 + 动量\n",
    "    \n",
    "    samples = 0 # 虚循环开始前，模型一个样本都没讲过\n",
    "    correct = 0 # 循环开始前，预测正确的数值为0\n",
    "\n",
    "    for epcho in range(epochs): # 全数据被训练几次\n",
    "        for batch_idx,(x, y) in enumerate(batchdata):\n",
    "            y = y.view(x.shape[0])  # 降维 很多算法要求标签y是一维的\n",
    "            sigma = net.forward(x)  # 正向传播\n",
    "            loss = criterion(sigma,y)\n",
    "            loss.backward()   # 反向传播\n",
    "            opt.step()   # 更新一步\n",
    "            opt.zero_grad()  # 梯度清零\n",
    "\n",
    "            # 求准确率 - 全部判断正确额样本数/已经看过的总样本数\n",
    "            yhat = torch.max(sigma,1)[1]  # torch.max() 返回结果中每一行的中的最大值\n",
    "            correct += torch.sum(yhat == y)   # 至今为止所有判断正确的样本\n",
    "            samples = samples + x.shape[0]  \n",
    "            #每一次循环都看了128(x.shape[0])个样本\n",
    "             \n",
    "            \n",
    "            # 每125个打印一次 or 整个批次跑到最后一个编号\n",
    "            if(batch_idx + 1) % 125 == 0 or batch_idx == len(batchdata) -1:   \n",
    "                print(('Epoch{}:[{}/{}({:.0f}%)]\\tLoss:{:.6f}\\t Accuracy:{:.3f}'.format   # 分子代表已经查看的数据/分母模型需要查看的数据\n",
    "                (\n",
    "                    epcho+1,\n",
    "                    samples,  # 已经看的数据\n",
    "                    len(batchdata.dataset)*epochs,   # 总共要看的数据\n",
    "                    100*samples/(len(batchdata.dataset)*epochs)\n",
    "                    ,loss.data.item() ,  # 损失函数\n",
    "                    float(correct*100)/samples   #准确率\n",
    "                    )\n",
    "                ))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batchdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'A')\n",
      "(1, 'B')\n",
      "(2, 'C')\n"
     ]
    }
   ],
   "source": [
    "# enumerate的用法\n",
    "list = ['A','B','C']\n",
    "for x in enumerate(list):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.4000, 0.2500],\n",
       "        [0.7000, 0.2000, 0.1000]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.max()的用法\n",
    "l = torch.tensor([[0.3,0.4,0.25],[0.7,0.2,0.1]])\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.7000, 0.4000, 0.2500]),\n",
       "indices=tensor([1, 0, 0]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(l,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.4000, 0.7000]),\n",
       "indices=tensor([1, 0]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.max(l,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4000, 0.7000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(l,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = torch.tensor([True,False,False])\n",
    "torch.sum(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-c21ba6090f11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 损失函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "# 损失函数\n",
    "loss.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.进行训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1:[16000/300000(5%)]\tLoss:0.469497\t Accuracy:75.075\n",
      "Epoch1:[32000/300000(11%)]\tLoss:0.513013\t Accuracy:79.231\n",
      "Epoch1:[48000/300000(16%)]\tLoss:0.402631\t Accuracy:80.902\n",
      "Epoch1:[60000/300000(20%)]\tLoss:0.399394\t Accuracy:81.685\n",
      "Epoch2:[76000/300000(25%)]\tLoss:0.399464\t Accuracy:82.578\n",
      "Epoch2:[92000/300000(31%)]\tLoss:0.304874\t Accuracy:83.182\n",
      "Epoch2:[108000/300000(36%)]\tLoss:0.353382\t Accuracy:83.634\n",
      "Epoch2:[120000/300000(40%)]\tLoss:0.358590\t Accuracy:83.933\n",
      "Epoch3:[136000/300000(45%)]\tLoss:0.320418\t Accuracy:84.304\n",
      "Epoch3:[152000/300000(51%)]\tLoss:0.341714\t Accuracy:84.678\n",
      "Epoch3:[168000/300000(56%)]\tLoss:0.537747\t Accuracy:84.970\n",
      "Epoch3:[180000/300000(60%)]\tLoss:0.340015\t Accuracy:85.139\n",
      "Epoch4:[196000/300000(65%)]\tLoss:0.335892\t Accuracy:85.391\n",
      "Epoch4:[212000/300000(71%)]\tLoss:0.284877\t Accuracy:85.630\n",
      "Epoch4:[228000/300000(76%)]\tLoss:0.323352\t Accuracy:85.839\n",
      "Epoch4:[240000/300000(80%)]\tLoss:0.337247\t Accuracy:85.961\n",
      "Epoch5:[256000/300000(85%)]\tLoss:0.328442\t Accuracy:86.142\n",
      "Epoch5:[272000/300000(91%)]\tLoss:0.230402\t Accuracy:86.312\n",
      "Epoch5:[288000/300000(96%)]\tLoss:0.198274\t Accuracy:86.446\n",
      "Epoch5:[300000/300000(100%)]\tLoss:0.189536\t Accuracy:86.546\n"
     ]
    }
   ],
   "source": [
    "# 实例化神经网络，调用优化算法需要的参数\n",
    "\n",
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_,out_features=output_)\n",
    "fit(net,batchdata,lr=lr,epochs=epochs,gamma=gamma)\n",
    "\n",
    "# 使用batch normalization的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的模型最后得到的结果属于中规中矩，毕竟我们设置的网格结构只是最普通的全连接层，并且我们并没有对数据进行任何的处理或增强。\n",
    "\n",
    "在神经网络架构中，有被注释掉的两行关于batch normalization的代码，取消注释，你会看到神经网络的准确率瞬间增加了5%，这是常用的处理之一 。\n",
    "\n",
    "准确率从83% -->86%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9c95e2fca121e63b81ef3e38ca658e3e94770f8b66e1c1e59a7460ee39b328d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
